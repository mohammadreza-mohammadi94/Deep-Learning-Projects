{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqzUKcSDWvnNCogcA2Wou+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Embeddings-and-Analogies/GloVe-Analogy-Solver/Glove_Analogy_Solver.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "FHeyCfgmR33o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLWP4dxTRzJk",
        "outputId": "8338f3ba-2148-4cb6-9c60-0033d2ac8294"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "id": "D4Xrb7QZR6JM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pre-Trained GloVe"
      ],
      "metadata": {
        "id": "FwRyKgMUSNXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading glove-wiki-gigaword-100...\")\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "print(\"Dataset downloaded successfully...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhwS7VygSMtO",
        "outputId": "284d9306-0c39-4a01-9a42-af4fd580e53c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading glove-wiki-gigaword-100...\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Dataset downloaded successfully...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "mkVqNOebSi9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Pre-computing normalized weights for speed...\")\n",
        "all_words = model.index_to_key\n",
        "word_vectors = model.vectors  # Shape: (400000, 100)\n",
        "# Normalize each row (vector) to unit length (L2 norm = 1)\n",
        "normalized_vectors = normalize(word_vectors, norm='l2', axis=1)\n",
        "\n",
        "def find_analogy(a, b, c, top_n=1):\n",
        "    \"\"\"\n",
        "    Solves the analogy A:B :: C:D (A is to B as C is to D)\n",
        "    Formula: D = argmax( cos(v_D, v_B - v_A + v_C) )\n",
        "    \"\"\"\n",
        "    # Check if words exist in vocabulary\n",
        "    for word in [a, b, c]:\n",
        "        if word not in model:\n",
        "            return f\"Error: '{word}' not found in vocabulary.\"\n",
        "\n",
        "    # Get vectors for A, B, and C\n",
        "    vec_a = model[a]\n",
        "    vec_b = model[b]\n",
        "    vec_c = model[c]\n",
        "\n",
        "    # Calculate target vector: v_B - v_A + v_C\n",
        "    target_vec = vec_b - vec_a + vec_c\n",
        "    # Normalize target vector for cosine similarity calculation\n",
        "    target_vec = target_vec / np.linalg.norm(target_vec)\n",
        "\n",
        "    # VECTORIZED SEARCH:\n",
        "    # Dot product of normalized_vectors (400k, 100) and target_vec (100,)\n",
        "    # Result is a vector of 400k similarity scores\n",
        "    similarities = np.dot(normalized_vectors, target_vec)\n",
        "\n",
        "    # Apply the constraint: Output cannot be A, B, or C\n",
        "    # We find indices of A, B, and C and set their similarity to -infinity\n",
        "    for word in [a, b, c]:\n",
        "        idx = model.key_to_index[word]\n",
        "        similarities[idx] = -np.inf\n",
        "\n",
        "    # Get the indices of top N results\n",
        "    best_indices = np.argsort(similarities)[-top_n:][::-1]\n",
        "\n",
        "    results = [(all_words[idx], similarities[idx]) for idx in best_indices]\n",
        "    return results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EamWxqCGSX0S",
        "outputId": "2a8211a8-c320-4020-9e4e-e779eb35b8a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-computing normalized weights for speed...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "fp8gMc3mSoaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    (\"man\", \"doctor\", \"woman\"),\n",
        "    (\"japan\", \"sushi\", \"germany\"),\n",
        "    (\"scientist\", \"einstein\", \"painter\"),\n",
        "    (\"tall\", \"tallest\", \"short\"),\n",
        "    (\"france\", \"paris\", \"italy\")\n",
        "]\n",
        "\n",
        "print(\"=\" * 40)\n",
        "print(\"\\tAnalogy Results\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "for a, b, c in test_cases:\n",
        "    prediction = find_analogy(a, b, c)\n",
        "    if isinstance(prediction, list):\n",
        "        print(f\"{a}:{b} :: {c}:?  =>  {prediction[0][0]} (Score: {prediction[0][1]:.4f})\")\n",
        "    else:\n",
        "        print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NWhnnytSn5S",
        "outputId": "b24357ac-8c24-4296-a13c-ae4ec18069ea"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "\tAnalogy Results\n",
            "========================================\n",
            "man:doctor :: woman:?  =>  nurse (Score: 0.7757)\n",
            "japan:sushi :: germany:?  =>  pastry (Score: 0.5280)\n",
            "scientist:einstein :: painter:?  =>  picasso (Score: 0.6477)\n",
            "tall:tallest :: short:?  =>  longest (Score: 0.6133)\n",
            "france:paris :: italy:?  =>  rome (Score: 0.8084)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cAP8KKGqSrM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}