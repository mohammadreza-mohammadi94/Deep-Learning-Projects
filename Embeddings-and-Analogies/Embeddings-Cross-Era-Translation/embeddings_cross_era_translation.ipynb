{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPH7Do9Voum376gpchQe+sv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Embeddings-and-Analogies/Embeddings-Cross-Era-Translation/embeddings_cross_era_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "xwE42iu0HjQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiYblQP4H6vJ",
        "outputId": "095993f2-34dd-4c33-9f0f-585a37400dcf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wvnC8LGHGfzn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gensim.downloader as api\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pre-trained Embedding Model"
      ],
      "metadata": {
        "id": "ZT7Be7qdHvYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading GloVe Model....\")\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9SWwkBUHr0Q",
        "outputId": "35841ad4-941f-489b-b0c8-ba8476e1328a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe Model....\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "xIvHYLgLIcxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_vector(pairs):\n",
        "    vectors = []\n",
        "    for ancient, modern in pairs:\n",
        "        if ancient in model and modern in model:\n",
        "            diff = model[modern] - model[ancient]\n",
        "            vectors.append(diff)\n",
        "        else:\n",
        "            print(f\"Warning: {ancient} or {modern} not found in the model.\")\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n",
        "\n",
        "def modernizer(ancient_word, time_vector, top_n=5):\n",
        "    if ancient_word not in model:\n",
        "        return f\"Word '{ancient_word}' not found.\"\n",
        "\n",
        "    target_vector = model[ancient_word] + time_vector\n",
        "    # Manual Cosine Similarity search for transparency\n",
        "    # We want to find words in the vocab that are closest to target_vector\n",
        "    # but excluding the input word itself.\n",
        "\n",
        "    similarities = model.most_similar(positive=[target_vector], topn=top_n + 1)\n",
        "    results = [word for word, score in similarities if word.lower() != ancient_word.lower()]\n",
        "    return results[:top_n]\n",
        ""
      ],
      "metadata": {
        "id": "GzgZagFbHsbS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training & Execution"
      ],
      "metadata": {
        "id": "SXU1LeLLJgf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "era_pairs = [\n",
        "    ('horse', 'car'),\n",
        "    ('candle', 'bulb'),\n",
        "    ('messenger', 'email'),\n",
        "    ('manuscript', 'pdf'),\n",
        "    ('alchemy', 'chemistry'),\n",
        "    ('sword', 'gun'),\n",
        "    ('carriage', 'bus'),\n",
        "    ('fortress', 'bunker')\n",
        "]\n",
        "\n",
        "v_time = get_time_vector(era_pairs)"
      ],
      "metadata": {
        "id": "9DjUj4zhHsYd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_words = ['chariot', 'scroll', 'castle', 'spear', 'amulet', 'scribe']\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"\\tCross-Era Translation Results\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for word in test_words:\n",
        "    modern_versions = modernizer(word, v_time)\n",
        "    print(f\"Ancient: {word.ljust(10)} -> Modern Potential: {modern_versions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38v6CSfIAEy",
        "outputId": "68d902e6-2d0e-42da-be3e-d69a143f89a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "\tCross-Era Translation Results\n",
            "==================================================\n",
            "Ancient: chariot    -> Modern Potential: ['wagons', 'tractor', 'wagon', 'chariots', 'carts']\n",
            "Ancient: scroll     -> Modern Potential: ['scrolls', 'click', 'caption', 'clicking', 'folder']\n",
            "Ancient: castle     -> Modern Potential: ['mansion', 'manor', 'house', 'residence', 'apartment']\n",
            "Ancient: spear      -> Modern Potential: ['knife', 'arrow', 'knives', 'projectile', 'fired']\n",
            "Ancient: amulet     -> Modern Potential: ['wallet', 'actuator', 'amulets', 'retrieves', 'pad']\n",
            "Ancient: scribe     -> Modern Potential: ['programmer', 'printer', 'scanner', 'copyist', 'translator']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AywZrYq5IABO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}