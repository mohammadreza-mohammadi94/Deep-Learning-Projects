# -*- coding: utf-8 -*-
"""Sentiment Analysis - RNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LJ1N1GvE1TnsBCUCXfpdUy9vBoRq3q4a
"""

from tensorflow.keras.layers import (SimpleRNN,
                                     LSTM,
                                     GRU,
                                     Embedding,
                                     Bidirectional,
                                     Dense)
from tensorflow.keras.models import Sequential
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing import sequence
import numpy as np

(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)

print(X_train.shape)
print(y_train.shape)
print(X_test.shape)
print(y_test.shape)

word_idx = imdb.get_word_index()
idx_word = {v: k for k, v in word_idx.items()}
print([idx_word[i] for i in X_train[0]])
# This reverses the mapping from word: index to index: word.

X_train = sequence.pad_sequences(X_train, maxlen=400)
X_test = sequence.pad_sequences(X_test, maxlen=400)

print(X_train.shape)
print(X_test.shape)

X_val, y_val = X_train[:64], y_train[:64]
X_train_, y_train_ = X_train[64:], y_train[64:]

print(X_val.shape)
print(y_val.shape)
print(X_train.shape)
print(y_train.shape)

# Check data types
print("Data types:")
print(f"X_train_ dtype: {X_train_.dtype}")
print(f"y_train_ dtype: {y_train_.dtype}")

# Check values ranges
print("\nValue ranges:")
print(f"X_train_ min: {X_train_.min()}, max: {X_train_.max()}")
print(f"y_train_ unique values: {np.unique(y_train_)}")  # Should be [0, 1]

# Check for any NaN values
print("\nNaN check:")
print(f"NaN in X_train_: {np.isnan(X_train_).any()}")
print(f"NaN in y_train_: {np.isnan(y_train_).any()}")

"""# Define Model

## 1. RNN
"""

embedding_size = 32

rnn_model = Sequential()
rnn_model.add(Embedding(5000,
                    embedding_size,
                    input_length=400))
rnn_model.add(SimpleRNN(128,
                    activation='relu',
                    return_sequences=False))
rnn_model.add(Dense(1, activation='sigmoid'))

rnn_model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])

rnn_model.summary()

hist_rnn = rnn_model.fit(X_train_, y_train_,
              batch_size=64,
              epochs=5,
              validation_data=(X_val, y_val),
              verbose=1)

rnn_model.evaluate(X_test, y_test)

"""## Gated Recurrent Unit (GRU)"""

gru_model = Sequential(name='GRU')
gru_model.add(Embedding(5000,
                    embedding_size,
                    input_length=400))
gru_model.add(GRU(128,
                    activation='tanh',
                    return_sequences=False))
gru_model.add(Dense(1, activation='sigmoid'))

gru_model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])

gru_model.summary()

hist_gru = gru_model.fit(X_train_, y_train_,
              batch_size=64,
              epochs=5,
              validation_data=(X_val, y_val),
              verbose=1)

gru_model.evaluate(X_test, y_test)

"""## 3. LSTM"""

lstm_model = Sequential(name="LSTM")
lstm_model.add(Embedding(5000,
                    embedding_size,
                    input_length=400))
lstm_model.add(LSTM(128,
                    activation='relu',
                    return_sequences=False))
lstm_model.add(Dense(1, activation='sigmoid'))

lstm_model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])

lstm_model.summary()

hist_lstm = lstm_model.fit(X_train_, y_train_,
              batch_size=64,
              epochs=5,
              validation_data=(X_val, y_val),
              verbose=1)

lstm_model.evaluate(X_test, y_test, verbose=False)

"""## Bidirectional LSTM"""

bi_lstm_model = Sequential(name="LSTM")
bi_lstm_model.add(Embedding(5000,
                    embedding_size,
                    input_length=400))
bi_lstm_model.add(Bidirectional(LSTM(128,
                    activation='relu',
                    return_sequences=False)))
bi_lstm_model.add(Dense(1, activation='sigmoid'))

bi_lstm_model.compile(loss='binary_crossentropy',
                optimizer='adam',
                metrics=['accuracy'])

bi_lstm_model.summary()

hist_bi_lstm = bi_lstm_model.fit(X_train_, y_train_,
              batch_size=64,
              epochs=5,
              validation_data=(X_val, y_val),
              verbose=1)

bi_lstm_model.evaluate(X_test, y_test, verbose=False)

