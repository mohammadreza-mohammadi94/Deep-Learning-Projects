# Toxic Comment Classification with CNN + GloVe Embeddings

This project trains a 1D Convolutional Neural Network (CNN) to classify toxic comments into multiple categories using pre-trained GloVe word embeddings.

---

## ðŸ§  Task

Multi-label classification on text data to detect:

- toxic
- severe_toxic
- obscene
- threat
- insult
- identity_hate

---

## ðŸ›  Model Architecture

- **Embedding Layer** with GloVe vectors (100d)
- **3 x Conv1D + MaxPooling** layers
- **GlobalMaxPooling**
- **Dense + Dropout**
- **Sigmoid Output** for multi-label classification

---

## ðŸ“Š Dataset

- Jigsaw Toxic Comment Classification Challenge (`train.csv`)
- Loaded and preprocessed using Keras Tokenizer & Padding

---

## ðŸ“ˆ Evaluation

- Loss: `Binary Crossentropy`
- Metrics: `Accuracy`, `ROC-AUC per label`
- Visualized training loss and accuracy over epochs

---

## ðŸš€ How to Run

1. Download [GloVe embeddings](https://nlp.stanford.edu/projects/glove/)
2. Update paths to `glove.6B.100d.txt` and `train.csv`
3. Run:

```bash
python toxic_cnn.py
```


## ðŸ“¦ Requirements

* TensorFlow / Keras
* Pandas, NumPy, Matplotlib
* scikit-learn
* GloVe (100d)

## ðŸ“Š Output

* Model summary
* Training/Validation plots
* ROC-AUC for each label

