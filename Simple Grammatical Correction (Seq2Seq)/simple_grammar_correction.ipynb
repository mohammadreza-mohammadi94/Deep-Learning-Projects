{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAnjfBHyGTsy8LN01KEzFc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Simple%20Grammatical%20Correction%20(Seq2Seq)/simple_grammar_correction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "nbuHFJBQS7uL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rIqPomK9S0hE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, RepeatVector, TimeDistributed, Embedding\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHRRh7klTEwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data\n",
        "*Ground Truth*"
      ],
      "metadata": {
        "id": "sMr7UdnrTKlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CORRECT_SENTENCES = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"i love to watch machine learning lectures\",\n",
        "    \"this is a very simple test sentence\",\n",
        "    \"the quick brown fox jumps over\",\n",
        "    \"neural networks are very powerful tools\"\n",
        "]\n",
        "\n",
        "# Add noise (Grammatical Errors)\n",
        "def inject_noise(sentences):\n",
        "    noisy_corpus = []\n",
        "    for sentence in sentences:\n",
        "        words = sentence.split()\n",
        "        if len(words) < 2:\n",
        "            noisy_corpus.append(sentence)\n",
        "            continue\n",
        "\n",
        "        # Random indices\n",
        "        swap_index = random.randint(0, len(words) - 2)\n",
        "        # Swap\n",
        "        words[swap_index], words[swap_index + 1] = words[swap_index + 1], words[swap_index]\n",
        "        noisy_corpus.append(' '.join(words))\n",
        "    return noisy_corpus\n",
        "\n",
        "# Generate dataset\n",
        "X_train_noisy = inject_noise(CORRECT_SENTENCES)\n",
        "Y_train_correct = CORRECT_SENTENCES\n",
        "\n",
        "print(f\"Input (Noisy) {X_train_noisy[0]}\")\n",
        "print(f\"Target (Correct) {Y_train_correct[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6ZFEY1zTNuo",
        "outputId": "1e4916f9-9a7e-4438-a8c8-b59b078ed3c6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input (Noisy) the cat sat on mat the\n",
            "Target (Correct) the cat sat on the mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hZgUr4cGT80Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenization\n",
        "*For Seq2Seq models we must vectorize both Input & Output (Convert to integers) and pad them*"
      ],
      "metadata": {
        "id": "OHFmyp1gUGgx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(oov_token=\"<unk>\")\n",
        "tokenizer.fit_on_texts(X_train_noisy + Y_train_correct)\n",
        "\n",
        "VOCAB_SIZE = len(tokenizer.word_index) + 1\n",
        "print(f\"Vocabulary Size: {VOCAB_SIZE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEZkvDEeUQZd",
        "outputId": "3011e1fe-dad2-45c4-e4cc-3984671181c3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to int\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train_noisy)\n",
        "Y_train_seq = tokenizer.texts_to_sequences(Y_train_correct)\n",
        "max_len = max([len(x) for x in X_train_seq + Y_train_seq])\n",
        "\n",
        "print(f\"Input Sequence: {X_train_seq[0]}\")\n",
        "print(f\"Target Sequence: {Y_train_seq[0]}\\n\\n\")\n",
        "\n",
        "# Padding\n",
        "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
        "Y_train_padded = pad_sequences(Y_train_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "print(f\"X_train_padded: {X_train_padded[0]}\")\n",
        "print(f\"Y_train_padded: {Y_train_padded[0]}\\n\\n\")\n",
        "\n",
        "# Add special tokens\n",
        "SOS_TOKEN_ID = 0\n",
        "Y_decoder_input = np.zeros((len(Y_train_padded), max_len))\n",
        "Y_decoder_input[:, 1:] = Y_train_padded[:, :-1]\n",
        "\n",
        "print(f\"Y_decoder_input: {Y_decoder_input[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1E888HvDUdlu",
        "outputId": "6a668fed-a1e3-4c99-d03f-316de21d8c13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sequence: [2, 4, 5, 6, 7, 2]\n",
            "Target Sequence: [2, 4, 5, 6, 2, 7]\n",
            "\n",
            "\n",
            "X_train_padded: [2 4 5 6 7 2 0]\n",
            "Y_train_padded: [2 4 5 6 2 7 0]\n",
            "\n",
            "\n",
            "Y_decoder_input: [0. 2. 4. 5. 6. 2. 7.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qZFFlpVUVkVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq (Encoder-Decoder) Model Definition"
      ],
      "metadata": {
        "id": "JRqhqbjHVhQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 32\n",
        "LSTM_UNITS = 32\n",
        "TARGET_LENGTH = max_len\n",
        "\n",
        "# Encoder\n",
        "encoder_inputs = Input(shape=(max_len, ), name=\"encoder_input\")\n",
        "encoder_emb = Embedding(\n",
        "    VOCAB_SIZE, EMBEDDING_DIM, name=\"encoder_embedding\")(encoder_inputs)\n",
        "_, encoder_state = GRU(LSTM_UNITS, return_state=True, name=\"encoder_gru\")(encoder_emb)\n",
        "\n",
        "# Decoder\n",
        "decoder_inputs = Input(shape=(TARGET_LENGTH, 1)) # Teacher forcing input\n",
        "decoder_gru = GRU(\n",
        "    LSTM_UNITS, return_sequences=True)(decoder_inputs, initial_state=encoder_state)\n",
        "output_layer = TimeDistributed(\n",
        "    Dense(VOCAB_SIZE, activation='softmax'))(decoder_gru)\n",
        "\n",
        "# Final model\n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=output_layer)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "1KREJEPoUrMz",
        "outputId": "9d44aba5-b69a-4f5b-e969-bf45828fc82a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m992\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_10      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru (\u001b[38;5;33mGRU\u001b[0m)   │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m),      │      \u001b[38;5;34m6,336\u001b[0m │ encoder_embeddin… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_7 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │      \u001b[38;5;34m3,360\u001b[0m │ input_layer_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │                   │            │ encoder_gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_4  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m31\u001b[0m)     │      \u001b[38;5;34m1,023\u001b[0m │ gru_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_embedding   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">992</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ input_layer_10      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)   │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>),      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,336</span> │ encoder_embeddin… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,360</span> │ input_layer_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │                   │            │ encoder_gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_4  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)     │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,023</span> │ gru_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,711\u001b[0m (45.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,711</span> (45.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,711\u001b[0m (45.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,711</span> (45.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_muznIIKWX36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "SUSml54CWiav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('best_reversal_model.keras', save_best_only=True, monitor='val_accuracy', mode='max'),\n",
        "    # EarlyStopping(monitor='val_loss', patience=35, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "print(\"\\n--- Starting Model Training with Teacher Forcing ---\")\n",
        "history = model.fit(\n",
        "    [X_train_padded, Y_decoder_input],\n",
        "    Y_train_padded,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    validation_split=0.2,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-pG4T90WiSR",
        "outputId": "b50fe3db-7c10-4e33-aed0-4c5596cf78bc"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Starting Model Training with Teacher Forcing ---\n",
            "Epoch 1/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.0357 - loss: 3.5987 - val_accuracy: 0.0000e+00 - val_loss: 3.7777\n",
            "Epoch 2/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.0357 - loss: 3.5793 - val_accuracy: 0.0000e+00 - val_loss: 3.7760\n",
            "Epoch 3/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1071 - loss: 3.5604 - val_accuracy: 0.0000e+00 - val_loss: 3.7745\n",
            "Epoch 4/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1429 - loss: 3.5419 - val_accuracy: 0.0000e+00 - val_loss: 3.7733\n",
            "Epoch 5/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1429 - loss: 3.5239 - val_accuracy: 0.0000e+00 - val_loss: 3.7722\n",
            "Epoch 6/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1429 - loss: 3.5063 - val_accuracy: 0.0000e+00 - val_loss: 3.7713\n",
            "Epoch 7/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.1429 - loss: 3.4891 - val_accuracy: 0.0000e+00 - val_loss: 3.7705\n",
            "Epoch 8/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1071 - loss: 3.4724 - val_accuracy: 0.0000e+00 - val_loss: 3.7697\n",
            "Epoch 9/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1071 - loss: 3.4560 - val_accuracy: 0.0000e+00 - val_loss: 3.7691\n",
            "Epoch 10/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1071 - loss: 3.4400 - val_accuracy: 0.0000e+00 - val_loss: 3.7685\n",
            "Epoch 11/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1071 - loss: 3.4245 - val_accuracy: 0.0000e+00 - val_loss: 3.7680\n",
            "Epoch 12/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1071 - loss: 3.4092 - val_accuracy: 0.0000e+00 - val_loss: 3.7675\n",
            "Epoch 13/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1071 - loss: 3.3944 - val_accuracy: 0.0000e+00 - val_loss: 3.7671\n",
            "Epoch 14/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.1071 - loss: 3.3799 - val_accuracy: 0.0000e+00 - val_loss: 3.7668\n",
            "Epoch 15/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.1071 - loss: 3.3657 - val_accuracy: 0.0000e+00 - val_loss: 3.7666\n",
            "Epoch 16/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1071 - loss: 3.3519 - val_accuracy: 0.0000e+00 - val_loss: 3.7664\n",
            "Epoch 17/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.1071 - loss: 3.3383 - val_accuracy: 0.0000e+00 - val_loss: 3.7665\n",
            "Epoch 18/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.1429 - loss: 3.3251 - val_accuracy: 0.0000e+00 - val_loss: 3.7667\n",
            "Epoch 19/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.1429 - loss: 3.3121 - val_accuracy: 0.0000e+00 - val_loss: 3.7670\n",
            "Epoch 20/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1429 - loss: 3.2994 - val_accuracy: 0.0000e+00 - val_loss: 3.7676\n",
            "Epoch 21/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1429 - loss: 3.2869 - val_accuracy: 0.0000e+00 - val_loss: 3.7683\n",
            "Epoch 22/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1429 - loss: 3.2746 - val_accuracy: 0.0000e+00 - val_loss: 3.7693\n",
            "Epoch 23/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1429 - loss: 3.2625 - val_accuracy: 0.0000e+00 - val_loss: 3.7705\n",
            "Epoch 24/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1429 - loss: 3.2506 - val_accuracy: 0.1429 - val_loss: 3.7720\n",
            "Epoch 25/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 3.2387 - val_accuracy: 0.1429 - val_loss: 3.7737\n",
            "Epoch 26/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.1429 - loss: 3.2270 - val_accuracy: 0.1429 - val_loss: 3.7756\n",
            "Epoch 27/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 3.2154 - val_accuracy: 0.1429 - val_loss: 3.7778\n",
            "Epoch 28/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.1429 - loss: 3.2037 - val_accuracy: 0.1429 - val_loss: 3.7803\n",
            "Epoch 29/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.1071 - loss: 3.1921 - val_accuracy: 0.1429 - val_loss: 3.7830\n",
            "Epoch 30/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.1071 - loss: 3.1805 - val_accuracy: 0.1429 - val_loss: 3.7860\n",
            "Epoch 31/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 3.1688 - val_accuracy: 0.1429 - val_loss: 3.7893\n",
            "Epoch 32/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.1429 - loss: 3.1570 - val_accuracy: 0.1429 - val_loss: 3.7927\n",
            "Epoch 33/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.1429 - loss: 3.1450 - val_accuracy: 0.1429 - val_loss: 3.7965\n",
            "Epoch 34/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.1429 - loss: 3.1329 - val_accuracy: 0.1429 - val_loss: 3.8004\n",
            "Epoch 35/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.1429 - loss: 3.1206 - val_accuracy: 0.1429 - val_loss: 3.8045\n",
            "Epoch 36/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1429 - loss: 3.1080 - val_accuracy: 0.1429 - val_loss: 3.8089\n",
            "Epoch 37/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.1429 - loss: 3.0951 - val_accuracy: 0.1429 - val_loss: 3.8134\n",
            "Epoch 38/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.1429 - loss: 3.0818 - val_accuracy: 0.1429 - val_loss: 3.8181\n",
            "Epoch 39/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1429 - loss: 3.0681 - val_accuracy: 0.1429 - val_loss: 3.8230\n",
            "Epoch 40/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1429 - loss: 3.0540 - val_accuracy: 0.1429 - val_loss: 3.8281\n",
            "Epoch 41/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 3.0393 - val_accuracy: 0.1429 - val_loss: 3.8333\n",
            "Epoch 42/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 3.0240 - val_accuracy: 0.1429 - val_loss: 3.8388\n",
            "Epoch 43/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.1429 - loss: 3.0079 - val_accuracy: 0.1429 - val_loss: 3.8444\n",
            "Epoch 44/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1429 - loss: 2.9912 - val_accuracy: 0.1429 - val_loss: 3.8503\n",
            "Epoch 45/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.1429 - loss: 2.9735 - val_accuracy: 0.1429 - val_loss: 3.8565\n",
            "Epoch 46/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1429 - loss: 2.9550 - val_accuracy: 0.1429 - val_loss: 3.8629\n",
            "Epoch 47/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.1429 - loss: 2.9356 - val_accuracy: 0.1429 - val_loss: 3.8698\n",
            "Epoch 48/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1429 - loss: 2.9153 - val_accuracy: 0.1429 - val_loss: 3.8771\n",
            "Epoch 49/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1429 - loss: 2.8943 - val_accuracy: 0.1429 - val_loss: 3.8849\n",
            "Epoch 50/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.1429 - loss: 2.8726 - val_accuracy: 0.1429 - val_loss: 3.8935\n",
            "Epoch 51/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.1429 - loss: 2.8506 - val_accuracy: 0.1429 - val_loss: 3.9028\n",
            "Epoch 52/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1786 - loss: 2.8287 - val_accuracy: 0.1429 - val_loss: 3.9130\n",
            "Epoch 53/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.1786 - loss: 2.8072 - val_accuracy: 0.1429 - val_loss: 3.9242\n",
            "Epoch 54/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.1786 - loss: 2.7867 - val_accuracy: 0.1429 - val_loss: 3.9363\n",
            "Epoch 55/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2143 - loss: 2.7672 - val_accuracy: 0.1429 - val_loss: 3.9492\n",
            "Epoch 56/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2500 - loss: 2.7488 - val_accuracy: 0.1429 - val_loss: 3.9625\n",
            "Epoch 57/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.2500 - loss: 2.7313 - val_accuracy: 0.1429 - val_loss: 3.9760\n",
            "Epoch 58/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.2143 - loss: 2.7142 - val_accuracy: 0.1429 - val_loss: 3.9893\n",
            "Epoch 59/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.2143 - loss: 2.6970 - val_accuracy: 0.1429 - val_loss: 4.0019\n",
            "Epoch 60/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.2500 - loss: 2.6795 - val_accuracy: 0.1429 - val_loss: 4.0137\n",
            "Epoch 61/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.2500 - loss: 2.6613 - val_accuracy: 0.1429 - val_loss: 4.0244\n",
            "Epoch 62/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.2857 - loss: 2.6426 - val_accuracy: 0.1429 - val_loss: 4.0340\n",
            "Epoch 63/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - accuracy: 0.3214 - loss: 2.6232 - val_accuracy: 0.1429 - val_loss: 4.0424\n",
            "Epoch 64/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3214 - loss: 2.6035 - val_accuracy: 0.1429 - val_loss: 4.0498\n",
            "Epoch 65/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.3214 - loss: 2.5834 - val_accuracy: 0.1429 - val_loss: 4.0561\n",
            "Epoch 66/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.3571 - loss: 2.5633 - val_accuracy: 0.1429 - val_loss: 4.0616\n",
            "Epoch 67/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.3571 - loss: 2.5432 - val_accuracy: 0.1429 - val_loss: 4.0665\n",
            "Epoch 68/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.3571 - loss: 2.5232 - val_accuracy: 0.1429 - val_loss: 4.0709\n",
            "Epoch 69/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.3571 - loss: 2.5035 - val_accuracy: 0.1429 - val_loss: 4.0751\n",
            "Epoch 70/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.4286 - loss: 2.4838 - val_accuracy: 0.1429 - val_loss: 4.0792\n",
            "Epoch 71/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.4643 - loss: 2.4642 - val_accuracy: 0.1429 - val_loss: 4.0835\n",
            "Epoch 72/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.4643 - loss: 2.4446 - val_accuracy: 0.1429 - val_loss: 4.0880\n",
            "Epoch 73/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.4643 - loss: 2.4247 - val_accuracy: 0.1429 - val_loss: 4.0927\n",
            "Epoch 74/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.4643 - loss: 2.4046 - val_accuracy: 0.1429 - val_loss: 4.0979\n",
            "Epoch 75/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.4643 - loss: 2.3842 - val_accuracy: 0.1429 - val_loss: 4.1035\n",
            "Epoch 76/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.4643 - loss: 2.3636 - val_accuracy: 0.1429 - val_loss: 4.1095\n",
            "Epoch 77/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.4643 - loss: 2.3427 - val_accuracy: 0.1429 - val_loss: 4.1158\n",
            "Epoch 78/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.5357 - loss: 2.3218 - val_accuracy: 0.1429 - val_loss: 4.1225\n",
            "Epoch 79/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.5357 - loss: 2.3009 - val_accuracy: 0.1429 - val_loss: 4.1293\n",
            "Epoch 80/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5357 - loss: 2.2800 - val_accuracy: 0.1429 - val_loss: 4.1363\n",
            "Epoch 81/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5357 - loss: 2.2591 - val_accuracy: 0.1429 - val_loss: 4.1433\n",
            "Epoch 82/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5357 - loss: 2.2384 - val_accuracy: 0.1429 - val_loss: 4.1502\n",
            "Epoch 83/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.5357 - loss: 2.2177 - val_accuracy: 0.1429 - val_loss: 4.1570\n",
            "Epoch 84/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5357 - loss: 2.1970 - val_accuracy: 0.1429 - val_loss: 4.1634\n",
            "Epoch 85/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.5357 - loss: 2.1765 - val_accuracy: 0.1429 - val_loss: 4.1696\n",
            "Epoch 86/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.5357 - loss: 2.1559 - val_accuracy: 0.1429 - val_loss: 4.1755\n",
            "Epoch 87/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5357 - loss: 2.1354 - val_accuracy: 0.1429 - val_loss: 4.1811\n",
            "Epoch 88/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.5357 - loss: 2.1150 - val_accuracy: 0.1429 - val_loss: 4.1863\n",
            "Epoch 89/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5357 - loss: 2.0946 - val_accuracy: 0.1429 - val_loss: 4.1913\n",
            "Epoch 90/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.5357 - loss: 2.0744 - val_accuracy: 0.1429 - val_loss: 4.1961\n",
            "Epoch 91/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.5357 - loss: 2.0543 - val_accuracy: 0.1429 - val_loss: 4.2007\n",
            "Epoch 92/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.5357 - loss: 2.0342 - val_accuracy: 0.0000e+00 - val_loss: 4.2051\n",
            "Epoch 93/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.5357 - loss: 2.0143 - val_accuracy: 0.0000e+00 - val_loss: 4.2094\n",
            "Epoch 94/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5357 - loss: 1.9946 - val_accuracy: 0.0000e+00 - val_loss: 4.2135\n",
            "Epoch 95/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.5357 - loss: 1.9749 - val_accuracy: 0.0000e+00 - val_loss: 4.2174\n",
            "Epoch 96/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 0.5357 - loss: 1.9553 - val_accuracy: 0.0000e+00 - val_loss: 4.2213\n",
            "Epoch 97/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.5357 - loss: 1.9359 - val_accuracy: 0.0000e+00 - val_loss: 4.2249\n",
            "Epoch 98/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 275ms/step - accuracy: 0.5357 - loss: 1.9165 - val_accuracy: 0.0000e+00 - val_loss: 4.2285\n",
            "Epoch 99/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.5357 - loss: 1.8972 - val_accuracy: 0.0000e+00 - val_loss: 4.2318\n",
            "Epoch 100/100\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step - accuracy: 0.5357 - loss: 1.8780 - val_accuracy: 0.0000e+00 - val_loss: 4.2350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "CuuINQm9WrwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "encoder_model = Model(encoder_inputs, encoder_state)\n",
        "\n",
        "decoder_state_input = Input(shape=(LSTM_UNITS,))\n",
        "decoder_input_single = Input(shape=(1,)) # Input shape for single token\n",
        "\n",
        "# Reshape the input to be 3D (batch_size, timesteps, features)\n",
        "decoder_input_reshaped = Reshape((1, 1))(decoder_input_single)\n",
        "\n",
        "dec_out, dec_state = GRU(LSTM_UNITS, return_sequences=True, return_state=True)(decoder_input_reshaped, initial_state=decoder_state_input)\n",
        "decoder_output_single = Dense(VOCAB_SIZE, activation='softmax')(dec_out)\n",
        "\n",
        "decoder_model = Model([decoder_input_single, decoder_state_input], [decoder_output_single, dec_state])"
      ],
      "metadata": {
        "id": "RNHEpr-kWiPO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xgZ0MDEEWyvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding Function"
      ],
      "metadata": {
        "id": "iKrFTzwjXDrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq_padded):\n",
        "    # 1. Get the initial state from the Encoder\n",
        "    state_value = encoder_model.predict(np.expand_dims(input_seq_padded, 0))\n",
        "\n",
        "    # 2. Start with the start-of-sequence token (SOS - assuming ID 1, if 0 is padding)\n",
        "    # Based on the tokenization and padding, the SOS token is not explicitly added\n",
        "    # and padding is 0. We should start with the first token of the target sequence during inference\n",
        "    # or use a dedicated SOS token if added during data preparation.\n",
        "    # For this example, let's assume we start with an arbitrary token and rely on the model's learning.\n",
        "    # A better approach would be to have a dedicated SOS token with a known ID.\n",
        "    # Given the current setup, let's start with the token ID for '<unk>' which is 1 based on the tokenizer.\n",
        "    next_token_id = tokenizer.word_index.get('<unk>', 1) # Use 1 as a fallback if <unk> not found\n",
        "\n",
        "    decoded_sequence_ids = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        # Current input for the Decoder: (1, 1, 1) - a single token\n",
        "        decoder_input_step = np.array([[next_token_id]])\n",
        "\n",
        "        # Predict the current step\n",
        "        output, state_value = decoder_model.predict([decoder_input_step, state_value])\n",
        "\n",
        "        # Get the ID of the token with the highest probability\n",
        "        sampled_token_id = np.argmax(output[0, -1, :])\n",
        "\n",
        "        # Stop if the end-of-sequence token is generated (assuming EOS is ID)\n",
        "        # Based on padding=post and max_len, 0 is used for padding.\n",
        "        # We can assume 0 as an implicit EOS token if the model learns to output it after the sequence.\n",
        "        if sampled_token_id == 0:\n",
        "            break\n",
        "\n",
        "        decoded_sequence_ids.append(sampled_token_id)\n",
        "\n",
        "        # Update the input for the next step\n",
        "        next_token_id = sampled_token_id\n",
        "\n",
        "    # Convert IDs to text\n",
        "    final_text = tokenizer.sequences_to_texts([decoded_sequence_ids])[0]\n",
        "    return final_text\n",
        "\n",
        "# --- Test Execution ---\n",
        "test_input = X_train_padded[0] # A training sample for testing\n",
        "test_input_text = X_train_noisy[0] # Get the original noisy text\n",
        "\n",
        "print(\"Original Noisy Text:\", test_input_text)\n",
        "print(\"Predicted Correct Text:\", decode_sequence(test_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V8tv2dHW3HT",
        "outputId": "f1287885-2c27-49d1-9800-03a01f220b5b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Noisy Text: the cat sat on mat the\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Predicted Correct Text: over over the test test test test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8p9WFahW7wR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}