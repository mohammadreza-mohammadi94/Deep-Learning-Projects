{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMWNg65Gjvvalwgfv7AZjBx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/NER%20Identification%20-%20Annotated%20GMB%20Corpus/ner_dentification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "UEecBf5i_VXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmo12nOE-hty",
        "outputId": "1a8356a8-3c12-41b6-a442-aee0a2b4c312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/kaggle/kaggle.json': No such file or directory\n",
            "Dataset URL: https://www.kaggle.com/datasets/shoumikgoswami/annotated-gmb-corpus\n",
            "License(s): DbCL-1.0\n",
            "Downloading annotated-gmb-corpus.zip to /content\n",
            "  0% 0.00/462k [00:00<?, ?B/s]\n",
            "100% 462k/462k [00:00<00:00, 930MB/s]\n",
            "Archive:  annotated-gmb-corpus.zip\n",
            "  inflating: GMB_dataset.txt         \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"KAGGLE_USERNAME\"] = userdata.get(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = userdata.get(\"KAGGLE_KEY\")\n",
        "\n",
        "!mkdir ~/kaggle\n",
        "!cp kaggle.json ~/kaggle\n",
        "!chmod 600 ~/kaggle/kaggle.json\n",
        "#!/bin/bash\n",
        "!kaggle datasets download shoumikgoswami/annotated-gmb-corpus\n",
        "!unzip annotated-gmb-corpus.zip\n",
        "!rm annotated-gmb-corpus.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "e9YK5_7d_XGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re"
      ],
      "metadata": {
        "id": "f4kC2-Ps_DT-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "jllQ-3FUBST2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\n",
        "    \"GMB_dataset.txt\",\n",
        "    sep='\\t',\n",
        "    header=0,\n",
        "    encoding='latin1',\n",
        "    names=['Index', 'Sentence #', 'Word', 'POS', 'Tag']\n",
        ")"
      ],
      "metadata": {
        "id": "BudyylUVEwXe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6N1PjMbLFsDx",
        "outputId": "f4ebe651-3e14-4d69-f4a9-5779fa51fb9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Index  Sentence #           Word  POS Tag\n",
              "0      0         1.0      Thousands  NNS   O\n",
              "1      1         1.0             of   IN   O\n",
              "2      2         1.0  demonstrators  NNS   O\n",
              "3      3         1.0           have  VBP   O\n",
              "4      4         1.0        marched  VBN   O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7fbb0dbb-dee9-4189-bb99-7c059cf343be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fbb0dbb-dee9-4189-bb99-7c059cf343be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7fbb0dbb-dee9-4189-bb99-7c059cf343be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7fbb0dbb-dee9-4189-bb99-7c059cf343be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-24329839-5208-4e0b-9eb4-db5d3d77f51c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-24329839-5208-4e0b-9eb4-db5d3d77f51c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-24329839-5208-4e0b-9eb4-db5d3d77f51c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 66161,\n  \"fields\": [\n    {\n      \"column\": \"Index\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19099,\n        \"min\": 0,\n        \"max\": 66160,\n        \"num_unique_values\": 66161,\n        \"samples\": [\n          25841,\n          5476,\n          49952\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sentence #\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 864.2862107282592,\n        \"min\": 1.0,\n        \"max\": 2999.0,\n        \"num_unique_values\": 2999,\n        \"samples\": [\n          1377.0,\n          933.0,\n          145.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8766,\n        \"samples\": [\n          \"unofficial\",\n          \"key\",\n          \"promised\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 41,\n        \"samples\": [\n          \"MD\",\n          \"WP\",\n          \"NN\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"O\",\n          \"B-geo\",\n          \"B-org\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30SyDYX4Ez4j",
        "outputId": "fd7301e5-69f5-46b7-b7f0-3badd5c08344"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66161 entries, 0 to 66160\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Index       66161 non-null  int64  \n",
            " 1   Sentence #  66161 non-null  float64\n",
            " 2   Word        66161 non-null  object \n",
            " 3   POS         66161 non-null  object \n",
            " 4   Tag         66161 non-null  object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 2.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Dataset"
      ],
      "metadata": {
        "id": "x-7g5DYDFSH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove NaNs\n",
        "df = df.dropna()\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25Kq-G-nACNk",
        "outputId": "1e8cb1cd-fe84-45f5-fb6f-a8baca42e6d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 66161 entries, 0 to 66160\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Index       66161 non-null  int64  \n",
            " 1   Sentence #  66161 non-null  float64\n",
            " 2   Word        66161 non-null  object \n",
            " 3   POS         66161 non-null  object \n",
            " 4   Tag         66161 non-null  object \n",
            "dtypes: float64(1), int64(1), object(3)\n",
            "memory usage: 2.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure only integers are in Sentence #\n",
        "# Convert 'Sentence #' to string type before using .str accessor\n",
        "df = df[df['Sentence #'].astype(str).str.contains('Sentence #', na=False) == False]\n",
        "\n",
        "# Convert 'Sentence #' to integer, coercing errors and dropping resulting NaNs\n",
        "df['Sentence #'] = pd.to_numeric(df['Sentence #'], errors='coerce')\n",
        "df = df.dropna(subset=['Sentence #'])\n",
        "df['Sentence #'] = df['Sentence #'].astype(int)"
      ],
      "metadata": {
        "id": "HkVBr2tEB1b6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAdJbgJlEYVi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the DataFrame by 'Sentence #' and aggregate 'Word' and 'Tag' into lists\n",
        "grouped_data = df.groupby('Sentence #')[['Word', 'Tag']].agg(list)\n",
        "\n",
        "# Create a list of tuples, where each tuple contains the list of words and list of tags for a sentence\n",
        "all_sentences = [\n",
        "    (row['Word'], row['Tag'])\n",
        "    for index, row in grouped_data.iterrows()\n",
        "]\n",
        "print(\"Grouping complete.\")\n",
        "\n",
        "# Print the total number of sentences extracted\n",
        "print(f\"\\nTotal number of sentences extracted: {len(all_sentences)}\")\n",
        "\n",
        "# If there are extracted sentences, print the first 3 and their lengths\n",
        "if all_sentences:\n",
        "    print(\"\\nFirst 3 sentences:\")\n",
        "    print(all_sentences[:3])\n",
        "\n",
        "    # Get the words and tags of the first sentence\n",
        "    first_words, first_tags = all_sentences[0]\n",
        "    # Print the length of words and tags in the first sentence\n",
        "    print(f\"\\nLength of words in the first sentence: {len(first_words)}\")\n",
        "    print(f\"Length of tags in the first sentence: {len(first_tags)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_m51J6GEYTF",
        "outputId": "62dc205f-9153-4d0e-96c1-ed65a09374c6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grouping complete.\n",
            "\n",
            "Total number of sentences extracted: 2999\n",
            "\n",
            "First 3 sentences:\n",
            "[(['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']), (['Families', 'of', 'soldiers', 'killed', 'in', 'the', 'conflict', 'joined', 'the', 'protesters', 'who', 'carried', 'banners', 'with', 'such', 'slogans', 'as', '\"', 'Bush', 'Number', 'One', 'Terrorist', '\"', 'and', '\"', 'Stop', 'the', 'Bombings', '.', '\"'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']), (['They', 'marched', 'from', 'the', 'Houses', 'of', 'Parliament', 'to', 'a', 'rally', 'in', 'Hyde', 'Park', '.'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'I-geo', 'O'])]\n",
            "\n",
            "Length of words in the first sentence: 24\n",
            "Length of tags in the first sentence: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5btKriY1JkH9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocab & Tokenization"
      ],
      "metadata": {
        "id": "JS-fUX76Keo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all unique words and tags\n",
        "all_words = set(word for sentence, tags in all_sentences for word in sentence)\n",
        "all_tags = set(tag for sentence, tags in all_sentences for tag in tags)\n",
        "print(f\"Total unique words: {len(all_words)}\")\n",
        "print(f\"Total unique tags: {len(all_tags)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSZ7CMdLJkGA",
        "outputId": "43998b4c-2137-4f1a-e0e4-e67ac96eb579"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total unique words: 8766\n",
            "Total unique tags: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping Dict\n",
        "# Create a mapping from each unique word to an integer index.\n",
        "# Start indexing from 2 to reserve 0 for padding and 1 for unknown words.\n",
        "word_to_index = {word: i + 2 for i, word in enumerate(sorted(list(all_words)))}\n",
        "word_to_index[\"<PAD>\"] = 0 # Add a mapping for the padding token\n",
        "word_to_index[\"<UNK>\"] = 1 # Add a mapping for unknown words\n",
        "\n",
        "# Create a mapping from each unique tag to an integer index.\n",
        "# Start indexing from 1 to reserve 0 for padding.\n",
        "tag_to_index = {tag: i + 1 for i, tag in enumerate(sorted(list(all_tags)))}\n",
        "tag_to_index[\"<PAD>\"] = 0 # Add a mapping for the padding tag\n",
        "\n",
        "# Inveresed Dict for inference model\n",
        "# Create an inverse mapping from integer index back to tag, useful for converting model predictions back to tags.\n",
        "index_to_tag = {i: t for t, i in tag_to_index.items()}\n",
        "\n",
        "\n",
        "# Split data to X/y\n",
        "# Convert the sentences (list of words) into a list of lists of integer indices using the word_to_index mapping.\n",
        "# If a word is not found in the mapping, use the index for the unknown token (1).\n",
        "X = [[word_to_index.get(word, 1) for word in sentence] for sentence, tags in all_sentences]\n",
        "# Convert the tags (list of tags) into a list of lists of integer indices using the tag_to_index mapping.\n",
        "y = [[tag_to_index[tag] for tag in tags] for sentence, tags in all_sentences]\n",
        "\n",
        "print(\"\\nExample of Conversion\")\n",
        "print(\"Original sentence (words):\", all_sentences[0][0])\n",
        "print(\"Converted sentence (integers):\", X[0])\n",
        "print(\"-\" * 30)\n",
        "print(\"Original tags:\", all_sentences[0][1])\n",
        "print(\"Converted tags (integers):\", y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPNEXP_fJkC7",
        "outputId": "7fa83b66-5621-4458-b204-2c13759e1a91"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of Conversion\n",
            "Original sentence (words): ['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "Converted sentence (integers): [2676, 6377, 4341, 5329, 6015, 8237, 1745, 8257, 6934, 8193, 8594, 5530, 1471, 3187, 4325, 8193, 8702, 6377, 745, 8360, 5121, 8191, 4143, 14]\n",
            "------------------------------\n",
            "Original tags: ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n",
            "Converted tags (integers): [17, 17, 17, 17, 17, 17, 3, 17, 17, 17, 17, 17, 3, 17, 17, 17, 17, 17, 4, 17, 17, 17, 17, 17]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xtc05BtxJj_v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding & Data Spliting"
      ],
      "metadata": {
        "id": "YuikCCsKLhRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "sentence_lengths = [len(s) for s in X]\n",
        "MAX_LEN = int(np.percentile(sentence_lengths, 95))\n",
        "print(f\"Using MAX_LEN = {MAX_LEN} (Covers 95% of sentences)\")\n",
        "\n",
        "# Padding\n",
        "X_padded = pad_sequences(\n",
        "    sequences=X,\n",
        "    maxlen=MAX_LEN,\n",
        "    padding=\"post\",\n",
        "    value=word_to_index[\"<PAD>\"]\n",
        ")\n",
        "\n",
        "y_padded = pad_sequences(\n",
        "    sequences=y,\n",
        "    maxlen=MAX_LEN,\n",
        "    padding='post',\n",
        "    value=tag_to_index['<PAD>']\n",
        ")\n",
        "\n",
        "# Split data to Train/Test\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_padded,\n",
        "    y_padded,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Increase dimension since \"SparseCategoricalCrossentropys\" expects it.\n",
        "y_train = np.expand_dims(y_train, axis=-1)\n",
        "y_test = np.expand_dims(y_test, axis=-1)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oM-hk1aLhI6",
        "outputId": "401f041e-1ae8-4253-cf54-cf77056c737a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using MAX_LEN = 36 (Covers 95% of sentences)\n",
            "X_train shape: (2399, 36)\n",
            "y_train shape: (2399, 36, 1)\n",
            "X_test shape: (600, 36)\n",
            "y_test shape: (600, 36, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download and Create GloVe Matrix"
      ],
      "metadata": {
        "id": "Jh4eS7oQP4sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word_to_index)  # Size of the vocabulary (number of unique words + padding and unknown tokens)\n",
        "NUM_TAGS = len(tag_to_index)      # Number of unique tags (including padding tag)\n",
        "# EMBEDDING_DIM = 200              # Dimension of the word embedding vectors\n",
        "# Define the path for the GloVe embeddings file\n",
        "GLOVE_PATH = 'glove.6B.100d.txt' # Use the 100-dimensional vectors\n",
        "GLOVE_ZIP_PATH = 'glove.6B.zip'\n",
        "\n",
        "# Check if the GloVe file already exists\n",
        "if not os.path.exists(GLOVE_PATH):\n",
        "    print(\"GloVe embeddings not found, downloading...\")\n",
        "    # Download GloVe embeddings\n",
        "    !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "    # Unzip the downloaded file\n",
        "    !unzip glove.6B.zip\n",
        "    # Clean up the zip file\n",
        "    !rm glove.6B.zip\n",
        "else:\n",
        "    print(\"GloVe embeddings found, skipping download.\")\n",
        "\n",
        "# Load GloVe vectors\n",
        "glove_vectors = {}\n",
        "with open(GLOVE_PATH, 'r', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], dtype='float32')\n",
        "        glove_vectors[word] = vector\n",
        "print(f\"Loaded {len(glove_vectors)} word vectors.\")\n",
        "\n",
        "# Create Embedding Matrix\n",
        "print(\"--- Creating Embedding Matrix ---\")\n",
        "# Correcting EMBEDDING_DIM to match the loaded GloVe vectors (100)\n",
        "EMBEDDING_DIM = 100\n",
        "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
        "for word, i in word_to_index.items():\n",
        "    vector = glove_vectors.get(word)\n",
        "    if vector is not None:\n",
        "        # Words present in both our vocabulary and GloVe\n",
        "        embedding_matrix[i] = vector\n",
        "    # Words not in GloVe (like <UNK> and <PAD>) will have zero vectors.\n",
        "print(\"Embedding Matrix created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToyqQ4h_LhGk",
        "outputId": "f999fa95-7a37-428d-ec24-428489eb4df5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GloVe embeddings found, skipping download.\n",
            "Loaded 400000 word vectors.\n",
            "--- Creating Embedding Matrix ---\n",
            "Embedding Matrix created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Definition"
      ],
      "metadata": {
        "id": "RWCn1r4sMNvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Embedding, Bidirectional,\n",
        "                                     LSTM, TimeDistributed, Dense,\n",
        "                                     Dropout)\n",
        "\n",
        "# Define constants for model architecture\n",
        "LSTM_UNITS = 256                 # Number of units in the LSTM layers\n",
        "\n",
        "# Model Architecture\n",
        "input_layer = Input(shape=(MAX_LEN,)) # Input layer that takes sequences of length MAX_LEN\n",
        "\n",
        "# Embedding layer to convert input word indices into dense vectors\n",
        "embedding_layer = Embedding(\n",
        "    input_dim=VOCAB_SIZE,\n",
        "    output_dim=EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    trainable=False,\n",
        "    mask_zero=True,  # Masking is enabled to ignore padding (value 0)\n",
        "    name=\"embedding_layer\"\n",
        ")(input_layer)\n",
        "\n",
        "# First Bidirectional LSTM layer\n",
        "# Processes the sequence in both forward and backward directions\n",
        "# return_sequences=True ensures that the output is a sequence\n",
        "# recurrent_dropout applies dropout to the recurrent connections\n",
        "bilstm_layer_1 = Bidirectional(\n",
        "    LSTM(units=LSTM_UNITS, return_sequences=True, recurrent_dropout=0.2),\n",
        "    name=\"bilstm_layer_1\"\n",
        ")(embedding_layer)\n",
        "\n",
        "# Second Bidirectional LSTM layer\n",
        "# Stacks another BiLSTM layer on top of the first one\n",
        "bilstm_layer_2 = Bidirectional(\n",
        "    LSTM(units=LSTM_UNITS, return_sequences=True, recurrent_dropout=0.2),\n",
        "    name=\"bilstm_layer_2\"\n",
        ")(bilstm_layer_1)\n",
        "\n",
        "# Dropout layer to prevent overfitting\n",
        "dropout_layer = Dropout(0.5, name=\"dropout_layer\")(bilstm_layer_2)\n",
        "\n",
        "# TimeDistributed Dense layer for output\n",
        "# Applies the Dense layer to each timestep of the sequence\n",
        "# The Dense layer has NUM_TAGS units with softmax activation for multi-class classification at each timestep\n",
        "output_layer = TimeDistributed(\n",
        "    Dense(NUM_TAGS, activation='softmax'),\n",
        "    name=\"output_layer\"\n",
        ")(dropout_layer)\n",
        "\n",
        "# Define the model by specifying the input and output layers\n",
        "model_improved = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# Compile the model\n",
        "# optimizer: Adam optimizer\n",
        "# loss: SparseCategoricalCrossentropy is used for integer targets (tags)\n",
        "# metrics: Accuracy is used to evaluate the model's performance\n",
        "model_improved.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model summary\n",
        "model_improved.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "DIbtaYN1LhD5",
        "outputId": "9013a7db-074c-4a7d-9777-b60b2120ab37"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m100\u001b[0m)   │    \u001b[38;5;34m876,800\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm_layer_1      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │    \u001b[38;5;34m731,136\u001b[0m │ embedding_layer[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm_layer_2      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │  \u001b[38;5;34m1,574,912\u001b[0m │ bilstm_layer_1[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bilstm_layer_2[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m18\u001b[0m)    │      \u001b[38;5;34m9,234\u001b[0m │ dropout_layer[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_layer     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">876,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm_layer_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">731,136</span> │ embedding_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bilstm_layer_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │ bilstm_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bilstm_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">9,234</span> │ dropout_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,192,082\u001b[0m (12.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,192,082</span> (12.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,315,282\u001b[0m (8.83 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,315,282</span> (8.83 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m876,800\u001b[0m (3.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">876,800</span> (3.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufVFW9u1MthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "9DP6zY9uMvR8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Define Early Stopping callback to prevent overfitting\n",
        "# monitor: quantity to be monitored (validation loss)\n",
        "# patience: number of epochs with no improvement after which training will be stopped\n",
        "# restore_best_weights: whether to restore model weights from the epoch with the best value of the monitored quantity\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Create sample weights to ignore padding in the loss calculation\n",
        "# We assign a weight of 1.0 to non-padding tags (y_train > 0) and 0.0 to padding tags (y_train == 0)\n",
        "sample_weights = np.where(y_train > 0, 1.0, 0.0)\n",
        "\n",
        "# Train the model\n",
        "# X_train, y_train: training data\n",
        "# epochs: number of training epochs\n",
        "# batch_size: number of samples per gradient update\n",
        "# validation_data: data on which to evaluate the loss and any model metrics at the end of each epoch\n",
        "# sample_weight: optional numpy array of weights for the training samples, used to weight the loss function\n",
        "# callbacks: list of callbacks to apply during training\n",
        "history = model_improved.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    sample_weight=sample_weights,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWnYd5MKMvIu",
        "outputId": "1f879563-c746-497a-e812-45d7d788a17d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 566ms/step - accuracy: 0.5069 - loss: 0.9199 - val_accuracy: 0.5330 - val_loss: 0.4029\n",
            "Epoch 2/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 510ms/step - accuracy: 0.5364 - loss: 0.3904 - val_accuracy: 0.5465 - val_loss: 0.3214\n",
            "Epoch 3/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 524ms/step - accuracy: 0.5408 - loss: 0.3248 - val_accuracy: 0.5519 - val_loss: 0.2981\n",
            "Epoch 4/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 520ms/step - accuracy: 0.5455 - loss: 0.2939 - val_accuracy: 0.5556 - val_loss: 0.2825\n",
            "Epoch 5/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 517ms/step - accuracy: 0.5544 - loss: 0.2651 - val_accuracy: 0.5553 - val_loss: 0.2729\n",
            "Epoch 6/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 519ms/step - accuracy: 0.5525 - loss: 0.2611 - val_accuracy: 0.5593 - val_loss: 0.2600\n",
            "Epoch 7/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 516ms/step - accuracy: 0.5563 - loss: 0.2354 - val_accuracy: 0.5579 - val_loss: 0.2637\n",
            "Epoch 8/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 519ms/step - accuracy: 0.5559 - loss: 0.2351 - val_accuracy: 0.5614 - val_loss: 0.2575\n",
            "Epoch 9/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 514ms/step - accuracy: 0.5666 - loss: 0.2146 - val_accuracy: 0.5612 - val_loss: 0.2491\n",
            "Epoch 10/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 501ms/step - accuracy: 0.5685 - loss: 0.2027 - val_accuracy: 0.5623 - val_loss: 0.2471\n",
            "Epoch 11/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 516ms/step - accuracy: 0.5640 - loss: 0.1996 - val_accuracy: 0.5606 - val_loss: 0.2471\n",
            "Epoch 12/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 513ms/step - accuracy: 0.5722 - loss: 0.1759 - val_accuracy: 0.5616 - val_loss: 0.2512\n",
            "Epoch 13/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 520ms/step - accuracy: 0.5670 - loss: 0.1741 - val_accuracy: 0.5598 - val_loss: 0.2573\n",
            "Epoch 14/20\n",
            "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 515ms/step - accuracy: 0.5702 - loss: 0.1607 - val_accuracy: 0.5613 - val_loss: 0.2608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "PqMNl_2DOoIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "loss, accuracy = model_improved.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print the test loss and accuracy\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqi788qeMvGJ",
        "outputId": "6f5645eb-05e7-4643-8dc4-fb14f14096d5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.2471\n",
            "Test Accuracy: 56.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = model_improved.predict(X_test)\n",
        "\n",
        "# Get the index of the tag with the highest probability for each word in each sentence\n",
        "predicted_tags_indices = np.argmax(predictions, axis=-1)\n",
        "\n",
        "# Remove the extra dimension from the true tags for easier comparison\n",
        "true_tags_indices = np.squeeze(y_test)\n",
        "\n",
        "# Flatten the true and predicted tags, excluding padding\n",
        "y_true_flat = []\n",
        "y_pred_flat = []\n",
        "\n",
        "# Iterate through each sentence in the test set\n",
        "for i in range(len(true_tags_indices)): # For each sentence\n",
        "    # Iterate through each token (word) in the current sentence\n",
        "    for j in range(len(true_tags_indices[i])): # For each token in the sentence\n",
        "        # Check if the true tag is not a padding tag\n",
        "        if true_tags_indices[i][j] != tag_to_index['<PAD>']:\n",
        "            # Append the true tag (converted back to string) to the flattened list\n",
        "            y_true_flat.append(index_to_tag[true_tags_indices[i][j]])\n",
        "            # Append the predicted tag (converted back to string) to the flattened list\n",
        "            y_pred_flat.append(index_to_tag[predicted_tags_indices[i][j]])\n",
        "\n",
        "# Get the names of the tags, excluding the padding tag\n",
        "tag_names = [tag for tag, index in tag_to_index.items() if index != 0]\n",
        "\n",
        "# Print the detailed classification report\n",
        "print(\"\\n--- Detailed Classification Report ---\")\n",
        "print(classification_report(y_true_flat, y_pred_flat, labels=tag_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHgGwDOFMvAR",
        "outputId": "18abcd11-69c9-467c-c0f3-82c4df95b83b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step\n",
            "\n",
            "--- Detailed Classification Report ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00        13\n",
            "       B-eve       1.00      0.10      0.18        10\n",
            "       B-geo       0.60      0.74      0.66       409\n",
            "       B-gpe       0.51      0.47      0.49       257\n",
            "       B-nat       0.00      0.00      0.00         8\n",
            "       B-org       0.40      0.28      0.33       248\n",
            "       B-per       0.58      0.62      0.60       215\n",
            "       B-tim       0.69      0.58      0.63       219\n",
            "       I-art       0.00      0.00      0.00         7\n",
            "       I-eve       1.00      0.20      0.33        10\n",
            "       I-geo       0.46      0.47      0.46        77\n",
            "       I-gpe       0.00      0.00      0.00        10\n",
            "       I-nat       0.00      0.00      0.00         5\n",
            "       I-org       0.53      0.54      0.54       182\n",
            "       I-per       0.70      0.79      0.74       252\n",
            "       I-tim       0.58      0.52      0.55        65\n",
            "           O       0.98      0.98      0.98     11161\n",
            "\n",
            "    accuracy                           0.92     13148\n",
            "   macro avg       0.47      0.37      0.38     13148\n",
            "weighted avg       0.92      0.92      0.92     13148\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5oG_77nYQ6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}