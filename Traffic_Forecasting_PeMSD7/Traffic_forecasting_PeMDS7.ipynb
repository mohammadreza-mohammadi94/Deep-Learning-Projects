{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Traffic_Forecasting_PeMSD7/Traffic_forecasting_PeMDS7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boDoi_q8JaCW"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6ce6S7aJK4y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHmukTiKJZwE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDsBEO75J0lK"
      },
      "source": [
        "# Configuration and Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDCNOrCYJZtX"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    FILE_PATH = \"PeMSD7_V_228.csv\"\n",
        "    INPUT_WINDOW = 12\n",
        "    OUTPUT_HORIZON = 12\n",
        "    SENSOR_TO_PROCESS = 0  # Index of the sensor column to use\n",
        "    TRAIN_RATIO = 0.7\n",
        "    VALIDATION_RATIO = 0.1\n",
        "    UNITS = 256\n",
        "    EPOCHS = 25\n",
        "    BATCH_SIZE = 64\n",
        "    PATIENCE = 10\n",
        "    SENSOR_TO_PLOT = 0  # Since we use one sensor, this is always 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_-4cIW1c3Lx",
        "outputId": "ed97ac49-5644-4f1a-d218-2cd0548c0f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n",
            "Is Built with CUDA:  True\n",
            "No GPU found.\n"
          ]
        }
      ],
      "source": [
        "# 1. Check if GPU is available and properly detected\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "print(\"Is Built with CUDA: \", tf.test.is_built_with_cuda())\n",
        "\n",
        "# 2. Verify GPU is being used by the session\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Optional: Configure GPU memory growth to prevent OOM errors\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU setup is OK.\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"GPU setup error: {e}\")\n",
        "else:\n",
        "    print(\"No GPU found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bp3q1496KWyl"
      },
      "source": [
        "# Load Traffic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbjSRXBYPUKF",
        "outputId": "0d785298-17f3-4d76-99f9-48ea91ee161c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-10-29 20:12:18--  https://raw.githubusercontent.com/VeritasYin/STGCN_IJCAI-18/refs/heads/master/dataset/PeMSD7_Full.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29211203 (28M) [application/zip]\n",
            "Saving to: ‘PeMSD7_Full.zip.2’\n",
            "\n",
            "PeMSD7_Full.zip.2   100%[===================>]  27.86M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-29 20:12:19 (237 MB/s) - ‘PeMSD7_Full.zip.2’ saved [29211203/29211203]\n",
            "\n",
            "Archive:  PeMSD7_Full.zip\n",
            "replace PeMSD7_V_228.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: PeMSD7_V_228.csv        \n",
            "  inflating: PeMSD7_V_1026.csv       \n",
            "  inflating: PeMSD7_W_228.csv        \n",
            "  inflating: PeMSD7_W_1026.csv       \n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/VeritasYin/STGCN_IJCAI-18/refs/heads/master/dataset/PeMSD7_Full.zip\n",
        "!unzip PeMSD7_Full.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BxulUR9JZqy"
      },
      "outputs": [],
      "source": [
        "def load_traffic_data(file_path: str) -> np.ndarray:\n",
        "    if not os.path.exists(file_path):\n",
        "        raise FileNotFoundError(f\"File not found: '{file_path}'.\")\n",
        "    df = pd.read_csv(file_path, header=None)  # The provided CSV has no header\n",
        "    return df.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDZFYiLNL-Uy"
      },
      "source": [
        "# Create `X`, `y`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trzCped6LZAu"
      },
      "outputs": [],
      "source": [
        "def create_sliding_windows(data: np.ndarray, input_window: int, output_horizon: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    X, y = [], []\n",
        "    total_timesteps = data.shape[0]\n",
        "    for i in range(total_timesteps - input_window - output_horizon + 1):\n",
        "        input_w = data[i: i + input_window, :]\n",
        "        output_h = data[i + input_window : i + input_window + output_horizon, :]\n",
        "        X.append(input_w)\n",
        "        y.append(output_h)\n",
        "    return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZW4RiQxJZn-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgqbMj6WMJ__"
      },
      "source": [
        "# Seq2Seq Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E83pX8qJKVkN"
      },
      "outputs": [],
      "source": [
        "def build_seq2seq_model(input_shape: tuple, output_horizon: int, num_sensors: int, units: int) -> Model:\n",
        "    \"\"\"\n",
        "    Builds a GRU-based Seq2Seq model with the corrected Functional API pattern.\n",
        "    \"\"\"\n",
        "    # === ENCODER ===\n",
        "    encoder_inputs = Input(shape=input_shape, name=\"encoder_input\")\n",
        "\n",
        "    # The first GRU layer's output is a single tensor.\n",
        "    encoder_gru1_outputs = GRU(units, return_sequences=True, name=\"encoder_gru1\")(encoder_inputs)\n",
        "\n",
        "    # **THE FIX IS HERE:** Call the second GRU and unpack its two outputs on the same line.\n",
        "    # We don't need the sequence output from this layer, only the state.\n",
        "    _, encoder_state = GRU(units, return_state=True, name=\"encoder_gru2\")(encoder_gru1_outputs)\n",
        "\n",
        "    # === DECODER ===\n",
        "    decoder_inputs = RepeatVector(output_horizon, name='repeat_vector')(encoder_state)\n",
        "\n",
        "    # We apply the same direct pattern here.\n",
        "    decoder_gru1_outputs = GRU(units, return_sequences=True, name='decoder_gru1')(decoder_inputs, initial_state=encoder_state)\n",
        "    decoder_gru2_outputs = GRU(units, return_sequences=True, name='decoder_gru2')(decoder_gru1_outputs)\n",
        "\n",
        "    # === OUTPUT LAYER ===\n",
        "    output_layer = TimeDistributed(Dense(num_sensors), name=\"output_layer\")\n",
        "    outputs = output_layer(decoder_gru2_outputs)\n",
        "\n",
        "    # Create and compile the final model\n",
        "    model = Model(encoder_inputs, outputs)\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykrNEk3TKViA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GzkeGBuNcUK"
      },
      "source": [
        "# Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80uW77jcKVfT"
      },
      "outputs": [],
      "source": [
        "def plot_prediction(y_true: np.ndarray, y_pred: np.ndarray, config: Config):\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    sensor_idx = config.SENSOR_TO_PLOT\n",
        "    true_values = y_true[:, sensor_idx]\n",
        "    predicted_values = y_pred[:, sensor_idx]\n",
        "    plt.plot(true_values, label='Ground Truth', color='blue', marker='o')\n",
        "    plt.plot(predicted_values, label='Prediction', color='red', linestyle='--', marker='x')\n",
        "    plt.title(f'Traffic Flow Prediction for Sensor #{sensor_idx}')\n",
        "    plt.xlabel(f'Time Step (in {config.OUTPUT_HORIZON*5}-min horizon)')\n",
        "    plt.ylabel('Traffic Flow')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "85BtUjBuKVce",
        "outputId": "9edd1893-5d76-4e17-a6de-d4dadbfaa3ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Loading Data\n",
            ">>> Preprocessing Data\n",
            "Training samples: X=(8847, 12, 1), y=(8847, 12, 1)\n",
            "Validation samples: X=(1244, 12, 1), y=(1244, 12, 1)\n",
            "Test samples: X=(2512, 12, 1), y=(2512, 12, 1)\n",
            ">>> Building Model\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,912</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)  │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ encoder_gru1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_gru2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_gru1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │                   │            │ encoder_gru2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_gru2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">394,752</span> │ decoder_gru1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ decoder_gru2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru1 (\u001b[38;5;33mGRU\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m198,912\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_gru2 (\u001b[38;5;33mGRU\u001b[0m)  │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m394,752\u001b[0m │ encoder_gru1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ repeat_vector       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ encoder_gru2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mRepeatVector\u001b[0m)      │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_gru1 (\u001b[38;5;33mGRU\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m394,752\u001b[0m │ repeat_vector[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │                   │            │ encoder_gru2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_gru2 (\u001b[38;5;33mGRU\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m394,752\u001b[0m │ decoder_gru1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │        \u001b[38;5;34m257\u001b[0m │ decoder_gru2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,383,425</span> (5.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,383,425\u001b[0m (5.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,383,425</span> (5.28 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,383,425\u001b[0m (5.28 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> Training Model\n",
            "Epoch 1/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 316ms/step - loss: 0.0547 - mean_absolute_error: 0.1566 - val_loss: 0.0256 - val_mean_absolute_error: 0.1271\n",
            "Epoch 2/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 316ms/step - loss: 0.0181 - mean_absolute_error: 0.0899 - val_loss: 0.0180 - val_mean_absolute_error: 0.0838\n",
            "Epoch 3/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 320ms/step - loss: 0.0164 - mean_absolute_error: 0.0794 - val_loss: 0.0178 - val_mean_absolute_error: 0.0895\n",
            "Epoch 4/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 307ms/step - loss: 0.0160 - mean_absolute_error: 0.0801 - val_loss: 0.0192 - val_mean_absolute_error: 0.0905\n",
            "Epoch 5/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 309ms/step - loss: 0.0165 - mean_absolute_error: 0.0806 - val_loss: 0.0177 - val_mean_absolute_error: 0.0839\n",
            "Epoch 6/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 315ms/step - loss: 0.0159 - mean_absolute_error: 0.0798 - val_loss: 0.0193 - val_mean_absolute_error: 0.1019\n",
            "Epoch 7/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 308ms/step - loss: 0.0161 - mean_absolute_error: 0.0824 - val_loss: 0.0198 - val_mean_absolute_error: 0.1011\n",
            "Epoch 8/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 307ms/step - loss: 0.0165 - mean_absolute_error: 0.0822 - val_loss: 0.0179 - val_mean_absolute_error: 0.0915\n",
            "Epoch 9/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 315ms/step - loss: 0.0159 - mean_absolute_error: 0.0801 - val_loss: 0.0186 - val_mean_absolute_error: 0.0880\n",
            "Epoch 10/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 308ms/step - loss: 0.0159 - mean_absolute_error: 0.0804 - val_loss: 0.0175 - val_mean_absolute_error: 0.0854\n",
            "Epoch 11/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 307ms/step - loss: 0.0150 - mean_absolute_error: 0.0756 - val_loss: 0.0177 - val_mean_absolute_error: 0.0826\n",
            "Epoch 12/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 307ms/step - loss: 0.0160 - mean_absolute_error: 0.0778 - val_loss: 0.0190 - val_mean_absolute_error: 0.0916\n",
            "Epoch 13/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 311ms/step - loss: 0.0161 - mean_absolute_error: 0.0807 - val_loss: 0.0177 - val_mean_absolute_error: 0.0864\n",
            "Epoch 14/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 307ms/step - loss: 0.0151 - mean_absolute_error: 0.0764 - val_loss: 0.0176 - val_mean_absolute_error: 0.0838\n",
            "Epoch 15/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - loss: 0.0148 - mean_absolute_error: 0.0752 - val_loss: 0.0179 - val_mean_absolute_error: 0.0816\n",
            "Epoch 16/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 314ms/step - loss: 0.0160 - mean_absolute_error: 0.0793 - val_loss: 0.0182 - val_mean_absolute_error: 0.0940\n",
            "Epoch 17/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 315ms/step - loss: 0.0156 - mean_absolute_error: 0.0790 - val_loss: 0.0183 - val_mean_absolute_error: 0.0844\n",
            "Epoch 18/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - loss: 0.0156 - mean_absolute_error: 0.0770 - val_loss: 0.0175 - val_mean_absolute_error: 0.0882\n",
            "Epoch 19/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 317ms/step - loss: 0.0151 - mean_absolute_error: 0.0772 - val_loss: 0.0179 - val_mean_absolute_error: 0.0845\n",
            "Epoch 20/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - loss: 0.0154 - mean_absolute_error: 0.0775 - val_loss: 0.0181 - val_mean_absolute_error: 0.0839\n",
            "Epoch 21/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - loss: 0.0156 - mean_absolute_error: 0.0787 - val_loss: 0.0175 - val_mean_absolute_error: 0.0835\n",
            "Epoch 22/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 317ms/step - loss: 0.0153 - mean_absolute_error: 0.0772 - val_loss: 0.0180 - val_mean_absolute_error: 0.0933\n",
            "Epoch 23/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 309ms/step - loss: 0.0153 - mean_absolute_error: 0.0772 - val_loss: 0.0183 - val_mean_absolute_error: 0.0837\n",
            "Epoch 24/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 308ms/step - loss: 0.0158 - mean_absolute_error: 0.0783 - val_loss: 0.0190 - val_mean_absolute_error: 0.1034\n",
            "Epoch 25/25\n",
            "\u001b[1m139/139\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 315ms/step - loss: 0.0156 - mean_absolute_error: 0.0826 - val_loss: 0.0177 - val_mean_absolute_error: 0.0892\n",
            ">>> Evaluating Model\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Arguments not recognized: {'drop_remainder': True}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1163661787.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Not enough test data to make a prediction.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1163661787.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> Evaluating Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_remainder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Loss (MSE): {test_loss:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Mean Absolute Error: {test_mae:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0muse_cached_eval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_use_cached_eval_dataset\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Arguments not recognized: {kwargs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_cached_eval_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Arguments not recognized: {'drop_remainder': True}"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    config = Config()\n",
        "\n",
        "    print(\">>> Loading Data\")\n",
        "    traffic_data_raw = load_traffic_data(config.FILE_PATH)\n",
        "    # BUG FIX: Select the sensor column while keeping it a 2D array.\n",
        "    # [:, config.SENSOR_TO_PROCESS] -> returns 1D array (WRONG)\n",
        "    # [:, [config.SENSOR_TO_PROCESS]] -> returns 2D array (CORRECT)\n",
        "    traffic_features = traffic_data_raw[:, [config.SENSOR_TO_PROCESS]]\n",
        "\n",
        "    print(\">>> Preprocessing Data\")\n",
        "    total_timesteps = traffic_features.shape[0]\n",
        "    train_end_idx = int(total_timesteps * config.TRAIN_RATIO)\n",
        "    val_end_idx = train_end_idx + int(total_timesteps * config.VALIDATION_RATIO)\n",
        "\n",
        "    train_data = traffic_features[:train_end_idx]\n",
        "    val_data = traffic_features[train_end_idx:val_end_idx]\n",
        "    test_data = traffic_features[val_end_idx:]\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    val_scaled = scaler.transform(val_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    X_train, y_train = create_sliding_windows(train_scaled, config.INPUT_WINDOW, config.OUTPUT_HORIZON)\n",
        "    X_val, y_val = create_sliding_windows(val_scaled, config.INPUT_WINDOW, config.OUTPUT_HORIZON)\n",
        "    X_test, y_test = create_sliding_windows(test_scaled, config.INPUT_WINDOW, config.OUTPUT_HORIZON)\n",
        "\n",
        "    # Check if any data was generated. If windows are too large, these might be empty.\n",
        "    if len(X_train) == 0 or len(X_val) == 0:\n",
        "        raise ValueError(\"Not enough data to create training/validation splits with the given window sizes.\")\n",
        "\n",
        "    print(f\"Training samples: X={X_train.shape}, y={y_train.shape}\")\n",
        "    print(f\"Validation samples: X={X_val.shape}, y={y_val.shape}\")\n",
        "    print(f\"Test samples: X={X_test.shape}, y={y_test.shape}\")\n",
        "\n",
        "    print(\">>> Building Model\")\n",
        "    num_sensors = X_train.shape[2]\n",
        "    model = build_seq2seq_model((config.INPUT_WINDOW, num_sensors), config.OUTPUT_HORIZON, num_sensors, config.UNITS)\n",
        "    model.summary()\n",
        "\n",
        "    print(\">>> Training Model\")\n",
        "    checkpoint = ModelCheckpoint('best_traffic_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=config.PATIENCE, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=config.EPOCHS,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        validation_data=(X_val, y_val),\n",
        "        callbacks=[checkpoint, early_stopping],\n",
        "        # Drop last batch if its size is not equal to BATCH_SIZE\n",
        "        # This is not strictly necessary anymore as we removed batch_shape, but it's good practice.\n",
        "    )\n",
        "\n",
        "    print(\">>> Evaluating Model\")\n",
        "    test_loss, test_mae = model.evaluate(X_test, y_test, batch_size=config.BATCH_SIZE, drop_remainder=True)\n",
        "    print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
        "    print(f\"Test Mean Absolute Error: {test_mae:.4f}\")\n",
        "\n",
        "    print(\">>> Making Predictions\")\n",
        "    sample_idx = 0\n",
        "    # Ensure test set has enough samples for a full batch for prediction if needed, or handle single prediction\n",
        "    if len(X_test) > 0:\n",
        "        input_sample = X_test[sample_idx:sample_idx+1]\n",
        "        ground_truth = y_test[sample_idx]\n",
        "\n",
        "        prediction_scaled = model.predict(input_sample)[0]\n",
        "\n",
        "        prediction_real = scaler.inverse_transform(prediction_scaled)\n",
        "        ground_truth_real = scaler.inverse_transform(ground_truth)\n",
        "\n",
        "        plot_prediction(ground_truth_real, prediction_real, config)\n",
        "    else:\n",
        "        print(\"Not enough test data to make a prediction.\")\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyX3pHUiNfJg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9sYHVFfvf1nf6UpD7poHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}