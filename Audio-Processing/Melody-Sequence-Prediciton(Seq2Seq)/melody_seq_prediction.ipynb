{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPB+CYsB8sV2jcoJeRZqJVE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Melody-Sequence-Prediciton(Seq2Seq)/melody_seq_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries Installation"
      ],
      "metadata": {
        "id": "n707s7cJ2cGY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w0ESZ68N2Wpd"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow pandas music21"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libs"
      ],
      "metadata": {
        "id": "NTBC7-W22gXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, TimeDistributed, Bidirectional, Dropout\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "d8nxHiFZ2euk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "V9UA8h3F3UxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_SEQ_LENGTH = 8     # Length of the sequence the model observes (Input Length)\n",
        "OUTPUT_SEQ_LENGTH = 8    # Length of the sequence the model predicts (Output Length)\n",
        "VOCAB_SIZE = 10          # Total unique notes/chords + special tokens\n",
        "EMBEDDING_DIM = 32\n",
        "LSTM_UNITS = 64\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 32\n",
        "PATIENCE = 10            # For EarlyStopping\n",
        "\n",
        "# --- Special Token IDs ---\n",
        "PAD_ID = 0 # Padding Token\n",
        "SOS_ID = 1 # Start of Sequence Token (used in Decoder Input)\n",
        "EOS_ID = 2 # End of Sequence Token (used to stop generation)\n",
        "# Actual notes/chords are IDs 3 to 9 (VOCAB_SIZE - 3)"
      ],
      "metadata": {
        "id": "z3p0WkdM2gMd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nq3djNSO2gKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "_TftTLb33jsn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a92bbfc0",
        "outputId": "6213ee52-7aab-4196-a9ed-80ad20ab1cfb"
      },
      "source": [
        "def create_synthetic_data(num_samples, input_len, output_len):\n",
        "    \"\"\"Generates sequences where Target[t] = Input[t+1] (Many-to-Many Aligned).\"\"\"\n",
        "    X_raw, Y_raw = [], []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        # Create a sequence of actual notes (IDs 3 to 9)\n",
        "        seq_len = random.randint(input_len, input_len + 3)\n",
        "        sequence = np.random.randint(3, VOCAB_SIZE, size=seq_len)\n",
        "\n",
        "        # Input X: The observed sequence (of length input_len)\n",
        "        input_seq = sequence[:input_len]\n",
        "\n",
        "        # Target Y: The next note (t+1) for each step in the input\n",
        "        target_seq_full = np.roll(sequence, -1)\n",
        "        target_seq = target_seq_full[:output_len]\n",
        "\n",
        "        X_raw.append(input_seq)\n",
        "        Y_raw.append(target_seq)\n",
        "\n",
        "    # Padding for X and final Target Y\n",
        "    X_padded = pad_sequences(X_raw, maxlen=input_len, padding='post', dtype='int32')\n",
        "    Y_target_padded = pad_sequences(Y_raw, maxlen=output_len, padding='post', value=EOS_ID)\n",
        "\n",
        "    # Teacher Forcing Input: Shifted Target with SOS at the beginning\n",
        "    Y_decoder_input = np.zeros((num_samples, output_len), dtype=np.int32)\n",
        "    Y_decoder_input[:, 0] = SOS_ID\n",
        "    Y_decoder_input[:, 1:] = Y_target_padded[:, :-1]\n",
        "\n",
        "    return X_padded, Y_decoder_input, Y_target_padded\n",
        "\n",
        "# Generate Data\n",
        "X_train, Y_dec_input, Y_target = create_synthetic_data(\n",
        "    5000, INPUT_SEQ_LENGTH, OUTPUT_SEQ_LENGTH)\n",
        "\n",
        "# Split for validation\n",
        "X_train, X_val, Y_target_train, Y_target_val = train_test_split(\n",
        "    X_train, Y_target, test_size=0.15, random_state=42\n",
        ")\n",
        "\n",
        "# --- CRITICAL FIX: Generate the corresponding Decoder Input for the Validation Set ---\n",
        "# The validation input for the decoder must mirror the structure of the training decoder input.\n",
        "Y_dec_val_input = np.zeros_like(Y_target_val)\n",
        "Y_dec_val_input[:, 0] = SOS_ID\n",
        "Y_dec_val_input[:, 1:] = Y_target_val[:, :-1]\n",
        "\n",
        "\n",
        "print(f\"Encoder Input Shape (X_train): {X_train.shape}\")\n",
        "print(f\"Decoder Input Shape (Y_dec_in): {Y_dec_input.shape}\")\n",
        "print(f\"Decoder Target Shape (Y_target): {Y_target.shape}\")\n",
        "print(f\"Example Target (First Sample): {Y_target[0]}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Input Shape (X_train): (4250, 8)\n",
            "Decoder Input Shape (Y_dec_in): (5000, 8)\n",
            "Decoder Target Shape (Y_target): (5000, 8)\n",
            "Example Target (First Sample): [6 8 8 5 9 9 7 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FLsi6KyH2gHz"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seq2Seq Model"
      ],
      "metadata": {
        "id": "Gq9cPOHiAY8B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- ENCODER ---\n",
        "encoder_inputs = Input(shape=(INPUT_SEQ_LENGTH,), name='encoder_input')\n",
        "encoder_emb = Embedding(VOCAB_SIZE, EMBEDDING_DIM)(encoder_inputs)\n",
        "# Encoder returns ONLY the final state (Context Vector)\n",
        "encoder_lstm = LSTM(LSTM_UNITS, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_emb) # LSTM returns h and c states\n",
        "\n",
        "# Keep only the states for the decoder\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "# --- DECODER ---\n",
        "decoder_inputs = Input(shape=(OUTPUT_SEQ_LENGTH,), name='decoder_input')\n",
        "decoder_emb = Embedding(VOCAB_SIZE, EMBEDDING_DIM)(decoder_inputs)\n",
        "\n",
        "\n",
        "# We set up our decoder to return full sequences, and to not return states.\n",
        "# The states are set by using the \"initial_state\" argument\n",
        "decoder_lstm = LSTM(LSTM_UNITS, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_emb, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "# Final Output Layer: Applies Dense to EACH of the 8 timesteps\n",
        "output_layer = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'))(decoder_outputs)\n",
        "\n",
        "# --- Define and Compile the final Model ---\n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=output_layer)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "Ks_S-R2o2gE3",
        "outputId": "3deebebc-8b70-4a2c-daf8-feaca4a1abe3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m320\u001b[0m │ encoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m320\u001b[0m │ decoder_input[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),      │     \u001b[38;5;34m24,832\u001b[0m │ embedding_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │                   │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m),   │     \u001b[38;5;34m24,832\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m),       │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
              "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)]       │            │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m10\u001b[0m)     │        \u001b[38;5;34m650\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_input       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ encoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ decoder_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ embedding_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │                   │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>),       │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
              "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)]       │            │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ time_distributed_1  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │                   │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,954\u001b[0m (199.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,954</span> (199.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,954\u001b[0m (199.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,954</span> (199.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    ModelCheckpoint('best_music_model.keras', save_best_only=True, monitor='val_loss', mode='min'),\n",
        "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    [X_train, Y_dec_input[:len(X_train)]], # Use the subset of Y_dec_input that corresponds to X_train\n",
        "    Y_target_train, # Target for the training set\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    # Pass the complete tuple for validation data: ([Encoder_Val_Input, Decoder_Val_Input], Target_Val_Output)\n",
        "    validation_data=([X_val, Y_dec_val_input], Y_target_val),\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyw-qpHlAjer",
        "outputId": "895f109c-1699-4d86-cf28-e492dd38781d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.1676 - loss: 2.0660 - val_accuracy: 0.2920 - val_loss: 1.7722\n",
            "Epoch 2/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.3136 - loss: 1.7233 - val_accuracy: 0.3783 - val_loss: 1.5822\n",
            "Epoch 3/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.3817 - loss: 1.5459 - val_accuracy: 0.4117 - val_loss: 1.4502\n",
            "Epoch 4/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.4274 - loss: 1.3973 - val_accuracy: 0.4573 - val_loss: 1.3067\n",
            "Epoch 5/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.4693 - loss: 1.2722 - val_accuracy: 0.4883 - val_loss: 1.2019\n",
            "Epoch 6/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5118 - loss: 1.1530 - val_accuracy: 0.5327 - val_loss: 1.0980\n",
            "Epoch 7/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5589 - loss: 1.0516 - val_accuracy: 0.5788 - val_loss: 1.0135\n",
            "Epoch 8/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.6065 - loss: 0.9535 - val_accuracy: 0.6282 - val_loss: 0.9211\n",
            "Epoch 9/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6565 - loss: 0.8626 - val_accuracy: 0.6777 - val_loss: 0.8239\n",
            "Epoch 10/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6994 - loss: 0.7752 - val_accuracy: 0.7058 - val_loss: 0.7526\n",
            "Epoch 11/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.7367 - loss: 0.6985 - val_accuracy: 0.7415 - val_loss: 0.6809\n",
            "Epoch 12/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7622 - loss: 0.6330 - val_accuracy: 0.7583 - val_loss: 0.6319\n",
            "Epoch 13/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7869 - loss: 0.5761 - val_accuracy: 0.7882 - val_loss: 0.5637\n",
            "Epoch 14/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.8135 - loss: 0.5147 - val_accuracy: 0.8095 - val_loss: 0.5070\n",
            "Epoch 15/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8358 - loss: 0.4609 - val_accuracy: 0.8247 - val_loss: 0.4666\n",
            "Epoch 16/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8478 - loss: 0.4233 - val_accuracy: 0.8333 - val_loss: 0.4458\n",
            "Epoch 17/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 0.3986 - val_accuracy: 0.8437 - val_loss: 0.4088\n",
            "Epoch 18/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8644 - loss: 0.3707 - val_accuracy: 0.8532 - val_loss: 0.3853\n",
            "Epoch 19/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.8767 - loss: 0.3460 - val_accuracy: 0.8565 - val_loss: 0.3755\n",
            "Epoch 20/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8787 - loss: 0.3310 - val_accuracy: 0.8598 - val_loss: 0.3625\n",
            "Epoch 21/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8838 - loss: 0.3183 - val_accuracy: 0.8647 - val_loss: 0.3521\n",
            "Epoch 22/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8892 - loss: 0.3054 - val_accuracy: 0.8728 - val_loss: 0.3362\n",
            "Epoch 23/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8888 - loss: 0.2987 - val_accuracy: 0.8710 - val_loss: 0.3299\n",
            "Epoch 24/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8917 - loss: 0.2915 - val_accuracy: 0.8732 - val_loss: 0.3272\n",
            "Epoch 25/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.8937 - loss: 0.2839 - val_accuracy: 0.8727 - val_loss: 0.3261\n",
            "Epoch 26/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8976 - loss: 0.2762 - val_accuracy: 0.8748 - val_loss: 0.3158\n",
            "Epoch 27/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9009 - loss: 0.2694 - val_accuracy: 0.8755 - val_loss: 0.3207\n",
            "Epoch 28/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9008 - loss: 0.2672 - val_accuracy: 0.8788 - val_loss: 0.3111\n",
            "Epoch 29/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9039 - loss: 0.2608 - val_accuracy: 0.8773 - val_loss: 0.3176\n",
            "Epoch 30/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.9029 - loss: 0.2591 - val_accuracy: 0.8770 - val_loss: 0.3118\n",
            "Epoch 31/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9020 - loss: 0.2605 - val_accuracy: 0.8750 - val_loss: 0.3197\n",
            "Epoch 32/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.2509 - val_accuracy: 0.8767 - val_loss: 0.3153\n",
            "Epoch 33/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9067 - loss: 0.2513 - val_accuracy: 0.8775 - val_loss: 0.3156\n",
            "Epoch 34/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9085 - loss: 0.2457 - val_accuracy: 0.8777 - val_loss: 0.3194\n",
            "Epoch 35/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9101 - loss: 0.2408 - val_accuracy: 0.8763 - val_loss: 0.3189\n",
            "Epoch 36/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9134 - loss: 0.2373 - val_accuracy: 0.8768 - val_loss: 0.3351\n",
            "Epoch 37/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9128 - loss: 0.2341 - val_accuracy: 0.8760 - val_loss: 0.3292\n",
            "Epoch 38/50\n",
            "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9172 - loss: 0.2288 - val_accuracy: 0.8798 - val_loss: 0.3228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6tYiEZCyAzPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}