{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbkC9E9vqWPATZPUzXarry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Text-Generation-Edgar-Allan-Poems/text_generation_edgar_allan_poems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import re"
      ],
      "metadata": {
        "id": "7U1sxJGxfQfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Dataset"
      ],
      "metadata": {
        "id": "GJbL-gKWfTQX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIwVG5QSen92",
        "outputId": "ff5ba718-5097-430b-bac2-a19149e2e8a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.gutenberg.org/cache/epub/10031/pg10031.txt\n",
            "\u001b[1m408498/408498\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "path = tf.keras.utils.get_file(\n",
        "    \"allan.tx\",\n",
        "    origin=\"https://www.gutenberg.org/cache/epub/10031/pg10031.txt\"\n",
        ")\n",
        "\n",
        "# Load all text\n",
        "text = open(path, \"rb\").read().decode(encoding=\"utf-8\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check few lines of text corpus\n",
        "print(text[2000:2500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy0WzOCxfOlA",
        "outputId": "b03c830e-88d9-4684-e303-d412f96f4ef8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n\r\n",
            "many additional pieces and extra stanzas, nowhere else published or\r\n",
            "included in Poe's works. Such verses have been gathered from printed or\r\n",
            "manuscript sources during a research extending over many years.\r\n",
            "\r\n",
            "In addition to the new poetical matter included in this volume,\r\n",
            "attention should, also, be solicited on behalf of the notes, which will\r\n",
            "be found to contain much matter, interesting both from biographical and\r\n",
            "bibliographical points of view.\r\n",
            "\r\n",
            "JOHN H. INGRAM.\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "CONTENTS.\r\n",
            "\r\n",
            "\r\n",
            "ME\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "BX6QOHsZfyqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(raw_text):\n",
        "    \"\"\"\n",
        "    Cleans the raw text data by removing project-specific headers/footers,\n",
        "    non-essential characters, and excessive whitespace.\n",
        "\n",
        "    Args:\n",
        "        raw_text (str): The raw text loaded from the source.\n",
        "\n",
        "    Returns:\n",
        "        str: The cleaned text.\n",
        "    \"\"\"\n",
        "    start_marker = \"EDGAR ALLAN POE\"\n",
        "    end_marker = \"End of the Project Gutenberg\"\n",
        "\n",
        "    # Find the main content between start and end markers\n",
        "    start_idx = raw_text.find(start_marker)\n",
        "    end_idx = raw_text.find(end_marker)\n",
        "\n",
        "    if start_idx != -1 and end_idx != -1:\n",
        "        text = raw_text[start_idx:end_idx]\n",
        "    else:\n",
        "        text = raw_text\n",
        "\n",
        "    lines = text.split('\\n')\n",
        "    clean_lines = []\n",
        "    for line in lines:\n",
        "        # Remove lines containing project Gutenberg related words\n",
        "        if not any(word in line.upper() for word in [\"GUTENBERG\", \"LICENSE\", \"FOUNDATION\", \"TRADEMARK\"]):\n",
        "            clean_lines.append(line)\n",
        "\n",
        "    text = '\\n'.join(clean_lines)\n",
        "\n",
        "    text = text.replace('\\r', '') # Remove carriage return characters\n",
        "    text = re.sub(r'\\[.*?\\]', '', text) # Remove text within square brackets (e.g., [Illustration])\n",
        "    text = re.sub(r'[0-9]+\\.[A-Z]\\.[0-9]+', '', text) # Remove license numbers like 1.D.6\n",
        "\n",
        "    # Limit characters to alphanumeric and essential punctuation\n",
        "    # This helps in creating a smaller and focused vocabulary\n",
        "    allowed_chars = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!,.?;: \\n'\"\n",
        "    text = ''.join([c for c in text if c in allowed_chars])\n",
        "\n",
        "    # Remove excessive blank lines\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n\\n', text) # Replace multiple blank lines with at most two\n",
        "\n",
        "    return text\n",
        "\n",
        "def create_vocab(text):\n",
        "    \"\"\"\n",
        "    Creates a vocabulary from the cleaned text, character-to-index and index-to-character mappings,\n",
        "    and converts the text into a numerical representation.\n",
        "\n",
        "    Args:\n",
        "        text (str): The cleaned text.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - vocab (list): Sorted list of unique characters.\n",
        "            - char2idx (dict): Mapping from character to integer index.\n",
        "            - idx2char (dict): Mapping from integer index to character.\n",
        "            - text_as_int (np.array): Numerical representation of the text.\n",
        "    \"\"\"\n",
        "    vocab = sorted(set(text))\n",
        "    char2idx = {char: idx for idx, char in enumerate(vocab)}\n",
        "    idx2char = {idx: char for idx, char in enumerate(vocab)}\n",
        "    text_as_int = np.array([char2idx[c] for c in text])\n",
        "    return vocab, char2idx, idx2char, text_as_int\n",
        "\n",
        "def prepare_dataset(text, batch_size, seq_length=100):\n",
        "    \"\"\"\n",
        "    Prepares the text data into a tf.data.Dataset for training a sequence model.\n",
        "    It creates sequences of characters and corresponding target sequences.\n",
        "\n",
        "    Args:\n",
        "        text (np.array): Numerical representation of the text.\n",
        "        batch_size (int): Number of sequences per batch.\n",
        "        seq_length (int, optional): Length of each input sequence. Defaults to 100.\n",
        "\n",
        "    Returns:\n",
        "        tf.data.Dataset: A batched and shuffled dataset of input-target sequence pairs.\n",
        "    \"\"\"\n",
        "    char_dataset = tf.data.Dataset.from_tensor_slices(text)\n",
        "    sequences = char_dataset.batch(seq_length + 1, drop_remainder=True)\n",
        "\n",
        "    def split_input_target(sequence):\n",
        "        # For each sequence, input is all characters except the last,\n",
        "        # and target is all characters except the first.\n",
        "        return sequence[:-1], sequence[1:]\n",
        "\n",
        "    dataset = sequences.map(split_input_target)\n",
        "    dataset = dataset.shuffle(10_000).batch(batch_size, drop_remainder=True)\n",
        "    return dataset\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    \"\"\"\n",
        "    Builds a character-level LSTM model using the Keras Sequential API.\n",
        "\n",
        "    Args:\n",
        "        vocab_size (int): The size of the vocabulary (number of unique characters).\n",
        "        embedding_dim (int): The dimension of the character embedding layer.\n",
        "        rnn_units (int): The number of units in the LSTM layers.\n",
        "        batch_size (int): The batch size for training/inference.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The compiled Keras model.\n",
        "    \"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(batch_shape=(batch_size, None)),\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units, return_sequences=True, stateful=True),\n",
        "\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def inference(weights, vocab_size, embedding_dim, rnn_units, batch_size=1):\n",
        "    \"\"\"\n",
        "    Loads a pre-trained model for inference. It rebuilds the model with a batch size of 1\n",
        "    and loads the specified weights.\n",
        "\n",
        "    Args:\n",
        "        weights (str): Path to the model weights file.\n",
        "        vocab_size (int): The size of the vocabulary.\n",
        "        embedding_dim (int): The dimension of the embedding layer.\n",
        "        rnn_units (int): The number of units in the LSTM layers.\n",
        "        batch_size (int, optional): Batch size for inference. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: The loaded model configured for inference.\n",
        "    \"\"\"\n",
        "    model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "    model.load_weights(weights)\n",
        "    model.build(tf.TensorShape([1, None]))\n",
        "    return model\n",
        "\n",
        "def generate(model, start_string, len, temp=0.7):\n",
        "    \"\"\"\n",
        "    Generates text using the trained character-level LSTM model.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): The trained Keras model.\n",
        "        start_string (str): The initial string to start text generation from.\n",
        "        len (int): The number of characters to generate.\n",
        "        temp (float, optional): Controls the randomness of prediction. Higher values\n",
        "                                 result in more unpredictable text. Defaults to 0.7.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated text, prefixed with the start_string.\n",
        "    \"\"\"\n",
        "    num_generation = len\n",
        "\n",
        "    # Convert start string to numerical representation\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0) # Add batch dimension (1, seq_length)\n",
        "\n",
        "    text_generated = []\n",
        "\n",
        "    # Reset the LSTM states before each generation to ensure independence\n",
        "    for layer in model.layers:\n",
        "        if hasattr(layer, \"reset_states\"):\n",
        "            layer.reset_states()\n",
        "\n",
        "    # Generate characters one by one\n",
        "    for i in range(num_generation):\n",
        "        predictions = model(input_eval)\n",
        "        # Remove the batch dimension (seq_length, vocab_size)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # Apply Temperature to modify the probability distribution for creativity\n",
        "        predictions = predictions / temp\n",
        "\n",
        "        # Sample a character from the predicted probability distribution\n",
        "        predicted_id = tf.random.categorical(\n",
        "            predictions, num_samples=1\n",
        "        )[-1, 0].numpy()\n",
        "\n",
        "        # Use the predicted character as the next input to the model\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "    return (start_string + \"\".join(text_generated))"
      ],
      "metadata": {
        "id": "p_TylPBxfmNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The raw text data is cleaned to remove irrelevant sections (like Project Gutenberg headers/footers),\n",
        "# special characters, and excessive whitespace, making it suitable for training.\n",
        "text = clean_text(text)\n",
        "\n",
        "# A vocabulary is created from the cleaned text. This involves:\n",
        "# - Extracting all unique characters to form the vocabulary.\n",
        "# - Creating mappings from characters to integer indices (char2idx) and vice-versa (idx2char).\n",
        "# - Converting the entire text into a numerical representation (text_as_int) using these mappings.\n",
        "vocab, char2idx, idx2char, text_as_int = create_vocab(text)\n",
        "\n",
        "# The numerical text is transformed into a TensorFlow `tf.data.Dataset`.\n",
        "# This dataset will provide sequences of characters as input and the next character in the sequence as the target,\n",
        "# batched and shuffled for efficient model training.\n",
        "dataset = prepare_dataset(text_as_int, 64)\n",
        "\n",
        "# Parameters for the LSTM model are defined, and the model architecture is built using these parameters.\n",
        "# - `vocab_size`: Total number of unique characters in the text, defining the output dimension of the last layer.\n",
        "# - `embedding_dim`: Dimension for the character embedding layer, converting character indices into dense vectors.\n",
        "# - `rnn_units`: Number of units in each LSTM layer, influencing the model's capacity to learn sequences.\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "model = build_model(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Display a summary of the model's architecture, including layer types, output shapes, and parameter counts.\n",
        "model.summary()\n",
        "\n",
        "# The model is compiled with a loss function and an optimizer, preparing it for the training process.\n",
        "# - `loss`: SparseCategoricalCrossentropy is used as it's suitable for integer-encoded targets and multi-class classification (predicting the next character).\n",
        "# - `optimizer`: Adam optimizer is chosen for its efficiency and good performance in various deep learning tasks, with an initial learning rate of 0.001.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "# Callbacks are configured to enhance the training process by saving model checkpoints, stopping early if performance plateaus,\n",
        "# and dynamically adjusting the learning rate.\n",
        "checkpoint_path = \"training_checkpoints/ckpt_{epoch}.weights.h5\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# 1. ModelCheckpoint:\n",
        "# Saves the model's weights during training. It monitors the 'loss' and saves only the best performing weights.\n",
        "# This ensures that if training improves, the best model state is preserved.\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='loss', # Monitor the training loss (since no validation data is used)\n",
        "    save_best_only=True # Save weights only when the monitored quantity improves\n",
        ")\n",
        "\n",
        "# 2. EarlyStopping:\n",
        "# Stops training if the model's performance (monitored via 'loss') does not improve for a specified number of epochs (patience).\n",
        "# The best weights from the epoch with the lowest loss will be restored.\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=5, # Stop if loss doesn't improve for 5 consecutive epochs\n",
        "    restore_best_weights=True # Restore model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "\n",
        "# 3. ReduceLROnPlateau:\n",
        "# Reduces the learning rate when the model's performance has stopped improving.\n",
        "# This helps the model to converge more precisely once it's close to an optimal solution.\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='loss',\n",
        "    factor=0.2, # Reduce learning rate by a factor of 0.2 (divide by 5)\n",
        "    patience=3, # Wait for 3 epochs of no improvement before reducing LR\n",
        "    min_lr=0.00001 # Set a lower bound for the learning rate\n",
        ")\n",
        "\n",
        "# Combine all defined callbacks into a list to be passed to the `fit` method.\n",
        "callbacks_list = [checkpoint_callback, early_stopping, reduce_lr]\n",
        "\n",
        "# The model is trained using the prepared dataset for a specified number of epochs, utilizing the defined callbacks.\n",
        "model.fit(dataset, epochs=50, callbacks=callbacks_list)\n",
        "\n",
        "# After training is complete, the final model weights are saved to a file.\n",
        "# This allows for later inference without needing to retrain the model.\n",
        "model.save_weights(\"edgar_allan.weights.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "KKrcwIVRgOgc",
        "outputId": "cff47a5b-335b-4d28-b2a7-486233f59b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m15,616\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_12 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m5,246,976\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m)         │        \u001b[38;5;34m62,525\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,616</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">5,246,976</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">62,525</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,110,525\u001b[0m (84.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,110,525</span> (84.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,110,525\u001b[0m (84.34 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,110,525</span> (84.34 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 290ms/step - loss: 3.4055 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 297ms/step - loss: 2.8157 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 309ms/step - loss: 2.2737 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 324ms/step - loss: 2.0465 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 325ms/step - loss: 1.8853 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - loss: 1.7473 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 314ms/step - loss: 1.6425 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 1.5603 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 1.4789 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 1.4135 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 1.3605 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 1.3031 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 1.2474 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 1.1971 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 1.1357 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 1.0767 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 1.0263 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.9648 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 0.8970 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 320ms/step - loss: 0.8403 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.7874 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.7300 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.6764 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 317ms/step - loss: 0.6316 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 0.5876 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.5427 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 316ms/step - loss: 0.5057 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 0.4741 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.4469 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 0.4246 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.4008 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.3836 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.3694 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.3516 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 316ms/step - loss: 0.3395 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 320ms/step - loss: 0.3278 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.3184 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.3109 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 0.3008 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 317ms/step - loss: 0.2936 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 0.2881 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 0.2826 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.2756 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 0.2726 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 320ms/step - loss: 0.2663 - learning_rate: 0.0010\n",
            "Epoch 46/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.2631 - learning_rate: 0.0010\n",
            "Epoch 47/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 321ms/step - loss: 0.2582 - learning_rate: 0.0010\n",
            "Epoch 48/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 317ms/step - loss: 0.2580 - learning_rate: 0.0010\n",
            "Epoch 49/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 318ms/step - loss: 0.2506 - learning_rate: 0.0010\n",
            "Epoch 50/50\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 319ms/step - loss: 0.2505 - learning_rate: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the saved model weights file.\n",
        "weights = \"/content/edgar_allan.weights.h5\"\n",
        "\n",
        "# Load the pre-trained model for inference.\n",
        "# The 'inference' function rebuilds the model with a batch size of 1 for single-prediction tasks,\n",
        "# and then loads the weights from the specified path.\n",
        "# It uses the previously defined vocabulary size, embedding dimension, and RNN units to reconstruct the model architecture.\n",
        "model_inference = inference(weights, vocab_size=vocab_size, embedding_dim=embedding_dim,\n",
        "                            rnn_units=rnn_units, batch_size=1)\n"
      ],
      "metadata": {
        "id": "uAPkn7xegVQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model_inference, start_string=\"Alice: \", len=800)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "Ztg9Cp52mhCe",
        "outputId": "1647e242-b603-468c-e912-3351e6f49c25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Alice: where he expired on the th of\\nOctober, , in the fortyfirst year of his age.\\n\\nEdgar Poe was editor of the 'Broadway Journal' for May .\\n\\n.   THE SLEEPER ERIST OF ANTHUN I\\nLCEIET DAR of The Pan, if you pale, est in the 'Se upon this new course of life with his\\nusual enthusiasm, and for a time to have borne the rigid violet beauty\\n              The unembodied essence, and no more\\n  Thy memory no more! Accursed ground\\n    Henceforward I hold thy flowerenamelled shadows so her anything it where the pieces referred to hinf\\n                 Fly that it must:\\n  Heaven shall chances apelyand the lightning did not flashand\\nthe cloud of the river, and the corrosive hours, comalted in my very hair!\\n\\n.\\n\\nTO HELEN.\\n\\n  Helen, thy beauty is to me\\n    Like those Nicean barks of yore,\\n  That gentle ways, and \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekt58pobn-xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZpGvlfLgNGOU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}