{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Poet%20Generator%20-%20Shakespeare's%20Sonnets/Poem_Generator_Shakespeare's_Sonnets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P7GoqNsfJig"
      },
      "source": [
        "# Import Libraries & Setup Enviorment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ki2MrNSnfA6s"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import requests\n",
        "import re\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "\n",
        "# Logging\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    handlers=[\n",
        "        logging.FileHandler('poetry_log.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2GQ8fl2f1Dn"
      },
      "source": [
        "# Define Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkiQ39znf2pt"
      },
      "source": [
        "*Download Dataset*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C8gMAUXfyh9"
      },
      "outputs": [],
      "source": [
        "def download_poetry_dataset():\n",
        "    dataset_path = \"shakespeare_sonnets.txt\"\n",
        "    url = \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
        "\n",
        "    if not os.path.exists(dataset_path):\n",
        "        try:\n",
        "            response = requests.get(url, stream=True)\n",
        "            with open(dataset_path, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "            logger.info(\"Dataset downloaded\")\n",
        "\n",
        "            # Remove metadata\n",
        "            with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "                lines = f.readlines()\n",
        "            start_idx = next(i for i, line in enumerate(lines) if \"SONNETS\" in line.upper()) + 1\n",
        "\n",
        "            with open(dataset_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.writelines(lines[start_idx:])\n",
        "            logger.info(\"Poetry dataset saved as shakespeare_sonnets.txt\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to download or process poetry dataset: {e}\")\n",
        "            raise\n",
        "    else:\n",
        "        logger.info(\"Poetry dataset already exists.\")\n",
        "    return dataset_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwQHKWq5hgqd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYXQqqL1jXQ0"
      },
      "source": [
        "*Preprocess*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CRaPdlnjYJc"
      },
      "outputs": [],
      "source": [
        "def preprocess_poetry(dataset_path, max_quatrain_length=40, max_words=5000):\n",
        "    logger.info(\"Preprocessing poetry data...\")\n",
        "    try:\n",
        "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
        "            text = f.read().lower()\n",
        "        # Remove noises\n",
        "        text = re.sub(r'[^\\w\\s\\b]', '', text)\n",
        "        text = re.sub(r'\\n+', '\\n', text)\n",
        "\n",
        "        # Split to lines\n",
        "        lines = text.split('\\n')\n",
        "        lines = [line.strip() for line in lines if line.strip() and not line.isspace()]\n",
        "\n",
        "        # Convert to Quatrains\n",
        "        # This code takes the lines of the poem from the lines list,\n",
        "        # converts each 4 lines into a string (quatrain),\n",
        "        # and adds it to the quatrains list if the number of words does not exceed\n",
        "        # the allowed limit.\n",
        "        # This is used to prepare the data for training the GRU model,\n",
        "        # since the model is going to be trained on quatrains.\n",
        "        quatrains = []                                              # empty list to store quatrains\n",
        "        for i in range(0, len(lines) - 3, 4):                       # creates lines in form of quatrains (4 lines by 4 lines)\n",
        "            if i + 3 < len(lines):                                  # checks if there are 4 lines available\n",
        "                quatrain = ' '.join(lines[i: i + 4])\n",
        "                if len(quatrain.split()) <= max_quatrain_length:\n",
        "                    quatrains.append(quatrain)\n",
        "\n",
        "        # Tokenization\n",
        "        tokenizer = Tokenizer(num_words = max_words, oov_token='<OOV>')\n",
        "        tokenizer.fit_on_texts(quatrains)\n",
        "        sequences = tokenizer.texts_to_sequences(quatrains)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=max_quatrain_length, padding='post')\n",
        "\n",
        "        # Spliting to X, t\n",
        "        X = padded_sequences[:, :-1]\n",
        "        y = padded_sequences[:, 1:]\n",
        "\n",
        "        logger.info(f\"Preprocessed {len(quatrains)} quatrains. X shape: {X.shape}, y shape: {y.shape}\")\n",
        "        return X, y, tokenizer, max_quatrain_length - 1\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in preprocessing poetry data: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMC8Cx9Qm7at"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_a7efMEnGDX"
      },
      "source": [
        "*Build GRU*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCrAX-LpnHio"
      },
      "outputs": [],
      "source": [
        "def build_gru_model(vocab_size, sequence_length):\n",
        "    logger.info(\"Building GRU Model...\")\n",
        "    try:\n",
        "        model = Sequential([\n",
        "            Embedding(vocab_size, 128, input_length=sequence_length),\n",
        "            GRU(256, return_sequences=True, dropout=0.2),\n",
        "            GRU(128, return_sequences=True, dropout=0.2),\n",
        "            TimeDistributed(Dense(vocab_size, activation='softmax'))\n",
        "        ])\n",
        "\n",
        "        model.compile(loss='sparse_categorical_crossentropy',\n",
        "                      optimizer='adam',\n",
        "                      metrics=['accuracy'])\n",
        "        logger.info(\"GRU model built successfully.\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error building model: {str(e)}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCY_Ltw_ntMm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULMaPw0Vnyic"
      },
      "source": [
        "*Generate Poem*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKpwXqXRn1nD"
      },
      "outputs": [],
      "source": [
        "def generate_poetry(model, tokenizer, sequence_length, max_length=40, temperature=1.0):\n",
        "    logger.info(\"Generating poetry...\")\n",
        "    try:\n",
        "        start_sequence = np.zeros((1, sequence_length))\n",
        "        seed_text = \"shall i compare thee to a summer's day\"\n",
        "        for i, word in enumerate(seed_text.lower().split()):\n",
        "            token = tokenizer.word_index.get(word, 1)  # 1 for OOV\n",
        "            if i < sequence_length:\n",
        "                start_sequence[0, i] = token\n",
        "\n",
        "        generated = seed_text.lower().split()\n",
        "        for _ in range(max_length - len(seed_text.split())):\n",
        "            pred = model.predict(start_sequence, verbose=0)\n",
        "            pred = np.log(pred + 1e-10) / temperature  # temperature\n",
        "            next_word_idx = np.argmax(pred[:, -1, :])\n",
        "            next_word = tokenizer.index_word.get(next_word_idx, '<OOV>')\n",
        "            if next_word == '<OOV>' or not next_word:\n",
        "                break\n",
        "            generated.append(next_word)\n",
        "            start_sequence = np.roll(start_sequence, -1)\n",
        "            start_sequence[0, -1] = next_word_idx\n",
        "\n",
        "        # convert to quatrains\n",
        "        poetry = ' '.join(generated)\n",
        "        quatrain_lines = [poetry[i:i + int(len(poetry.split())/4)].strip() for i in range(0, len(poetry.split()), int(len(poetry.split())/4))]\n",
        "        while len(quatrain_lines) < 4:\n",
        "            quatrain_lines.append(\"\")\n",
        "        return '\\n'.join(quatrain_lines[:4])\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating poetry: {e}\")\n",
        "        raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1ZJy42Mn7mK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trLNXAiFn8Cy"
      },
      "source": [
        "# Run Functions and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 682
        },
        "id": "x4wLkL1Pn-wx",
        "outputId": "6d3bbf9b-dbdc-4052-9847-17c4f4cdc18c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ time_distributed                │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m927/927\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2821s\u001b[0m 3s/step - accuracy: 0.4067 - loss: 4.9293 - val_accuracy: 0.4229 - val_loss: 4.0504\n",
            "Epoch 2/100\n",
            "\u001b[1m296/927\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:43\u001b[0m 3s/step - accuracy: 0.4328 - loss: 3.8353"
          ]
        }
      ],
      "source": [
        "logger.info(\"Starting poetry generation project...\")\n",
        "\n",
        "# Download dataset\n",
        "dataset_path = download_poetry_dataset()\n",
        "\n",
        "# Preprocessing\n",
        "X, y, tokenizer, sequence_length = preprocess_poetry(dataset_path)\n",
        "\n",
        "# Build and train the model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model = build_gru_model(vocab_size, sequence_length)\n",
        "model.summary()\n",
        "\n",
        "logger.info(\"Training GRU Model...\")\n",
        "y = np.expand_dims(y, -1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               restore_best_weights=True)\n",
        "model.fit(X, y, epochs=10,\n",
        "          batch_size=32,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stopping])\n",
        "logger.info(\"Training completed.\")\n",
        "\n",
        "# Generate poet\n",
        "poetry = generate_poetry(model, tokenizer, sequence_length, temperature=0.7)\n",
        "logger.info(\"Generated poetry:\\n\" + poetry)\n",
        "\n",
        "# Save the model\n",
        "model.save(\"quatrains_poetry_gru_model.h5\")\n",
        "logger.info(\"Model saved as poetry_gru_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LkLoLmJo0sV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}