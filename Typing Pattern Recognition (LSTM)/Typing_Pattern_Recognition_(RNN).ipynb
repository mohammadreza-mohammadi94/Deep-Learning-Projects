{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBeNHQb0xqdHTj3/ym8U2n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohammadreza-mohammadi94/Deep-Learning-Projects/blob/main/Typing%20Pattern%20Recognition%20(LSTM)/Typing_Pattern_Recognition_(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Frameworks & Setup Enviorment"
      ],
      "metadata": {
        "id": "Ou142wrPvuOm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t4C3kv0RmsKK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(\n",
        "    format=(\"%(asctime)s - %(levelname)s - %(message)s\"),\n",
        "    level=logging.INFO,\n",
        "    handlers=[\n",
        "        logging.FileHandler('app_logs.log'),\n",
        "        logging.StreamHandler()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "n9AQACCWxB_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_keystroke_dataset(file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Chose features\n",
        "    feature_columns = [col for col in df.columns if col.startswith(('H.', 'DD.', 'UD.'))]\n",
        "    df_features = df[feature_columns]\n",
        "\n",
        "    # Normalization Data\n",
        "    df_features = (df_features - df_features.min()) / (df_features.max() - df_features.min())\n",
        "\n",
        "    # Creating sequences for each user\n",
        "    sequences = []\n",
        "    user_groups = df.groupby('subject')\n",
        "\n",
        "    for user_id, group in user_groups:\n",
        "        seq = group[feature_columns].values\n",
        "        sequences.append(seq)\n",
        "\n",
        "    print(\"Number of Users: \", len(user_groups))\n",
        "    print(\"Number of Features: \", len(feature_columns))\n",
        "    return sequences, feature_columns\n"
      ],
      "metadata": {
        "id": "ruTn_ccoowZ4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "5T6ewdmaze8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(sequences, max_len=20):\n",
        "    X, y = [], []\n",
        "    for seq in sequences:\n",
        "        for i in range(len(seq) - 1):\n",
        "            X.append(seq[max(0, i - max_len + 1): i + 1])\n",
        "            y.append(seq[i + 1])\n",
        "    X = pad_sequences(X, maxlen=max_len, padding='pre', dtype='float32')\n",
        "    y = np.array(y, dtype='float32')\n",
        "\n",
        "    print(f\"Number of Sequences: {len(X)}\")\n",
        "    print(f\"Input Dimension: {X.shape}\")\n",
        "    print(f\"Output Dimension: {y.shape}\")\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "vs-Sv3Xdy6HG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the Model"
      ],
      "metadata": {
        "id": "xB3eTnjx0JkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(input_shape, output_dim):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = LSTM(64, return_sequences=False)(inputs)\n",
        "    x = Dense(32, activation='relu')(x)\n",
        "    outputs = Dense(output_dim, activation='linear')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer = Adam(learning_rate=0.01),\n",
        "                  loss='mse',\n",
        "                  metrics=['mae'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "_NUHaAsj0I1r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction Method"
      ],
      "metadata": {
        "id": "qgyKgnPK1FJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_pattern(model, sequence, max_len):\n",
        "    padded_sequence = pad_sequences([sequence[-max_len:]], maxlen=max_len, padding='pre', dtype='float32')\n",
        "    prediction = model.predict(padded_sequence, verbose=0)\n",
        "    return prediction[0]"
      ],
      "metadata": {
        "id": "g_FJk4250kzy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run And Train the Model"
      ],
      "metadata": {
        "id": "nRDdeYjm1ahX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/DSL-StrongPasswordData.csv'\n",
        "# Load & preprocess\n",
        "sequences, feature_columns = load_keystroke_dataset(file_path)\n",
        "\n",
        "# data preparation\n",
        "max_len = 20\n",
        "X, y = prepare_data(sequences, max_len)\n",
        "\n",
        "# input output dimension\n",
        "input_shape = (max_len, X.shape[2])\n",
        "output_dim = X.shape[2]\n",
        "\n",
        "# build and train the model\n",
        "model = build_model(input_shape, output_dim)\n",
        "model.summary()\n",
        "# train the model\n",
        "history = model.fit(X, y, batch_size=32, epochs=50, validation_split=0.2, verbose=1)\n",
        "\n",
        "# saving the model\n",
        "model.save('keystroke_pattern_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3y9Bud3c1aCd",
        "outputId": "72e357f4-4998-4f2e-90eb-1adcf8835a24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Users:  51\n",
            "Number of Features:  31\n",
            "Number of Sequences: 20349\n",
            "Input Dimension: (20349, 20, 31)\n",
            "Output Dimension: (20349, 31)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m31\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m24,576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m)             │         \u001b[38;5;34m1,023\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,023</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,679\u001b[0m (108.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,679</span> (108.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,679\u001b[0m (108.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,679</span> (108.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - loss: 0.0172 - mae: 0.0663 - val_loss: 0.0286 - val_mae: 0.0575\n",
            "Epoch 2/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0133 - mae: 0.0533 - val_loss: 0.0285 - val_mae: 0.0544\n",
            "Epoch 3/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0131 - mae: 0.0523 - val_loss: 0.0272 - val_mae: 0.0507\n",
            "Epoch 4/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0151 - mae: 0.0514 - val_loss: 0.0274 - val_mae: 0.0525\n",
            "Epoch 5/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0134 - mae: 0.0505 - val_loss: 0.0275 - val_mae: 0.0516\n",
            "Epoch 6/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0124 - mae: 0.0504 - val_loss: 0.0272 - val_mae: 0.0526\n",
            "Epoch 7/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0130 - mae: 0.0504 - val_loss: 0.0269 - val_mae: 0.0552\n",
            "Epoch 8/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0125 - mae: 0.0498 - val_loss: 0.0272 - val_mae: 0.0525\n",
            "Epoch 9/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0125 - mae: 0.0499 - val_loss: 0.0275 - val_mae: 0.0531\n",
            "Epoch 10/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0123 - mae: 0.0489 - val_loss: 0.0274 - val_mae: 0.0521\n",
            "Epoch 11/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0135 - mae: 0.0500 - val_loss: 0.0270 - val_mae: 0.0508\n",
            "Epoch 12/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0124 - mae: 0.0490 - val_loss: 0.0263 - val_mae: 0.0529\n",
            "Epoch 13/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0119 - mae: 0.0492 - val_loss: 0.0265 - val_mae: 0.0516\n",
            "Epoch 14/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0122 - mae: 0.0493 - val_loss: 0.0270 - val_mae: 0.0564\n",
            "Epoch 15/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0123 - mae: 0.0490 - val_loss: 0.0270 - val_mae: 0.0505\n",
            "Epoch 16/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0130 - mae: 0.0491 - val_loss: 0.0274 - val_mae: 0.0545\n",
            "Epoch 17/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0123 - mae: 0.0494 - val_loss: 0.0271 - val_mae: 0.0526\n",
            "Epoch 18/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0125 - mae: 0.0486 - val_loss: 0.0267 - val_mae: 0.0531\n",
            "Epoch 19/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 0.0125 - mae: 0.0490 - val_loss: 0.0273 - val_mae: 0.0544\n",
            "Epoch 20/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 13ms/step - loss: 0.0122 - mae: 0.0489 - val_loss: 0.0266 - val_mae: 0.0550\n",
            "Epoch 21/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - loss: 0.0124 - mae: 0.0493 - val_loss: 0.0266 - val_mae: 0.0517\n",
            "Epoch 22/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0127 - mae: 0.0492 - val_loss: 0.0273 - val_mae: 0.0537\n",
            "Epoch 23/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0129 - mae: 0.0499 - val_loss: 0.0274 - val_mae: 0.0524\n",
            "Epoch 24/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0118 - mae: 0.0488 - val_loss: 0.0273 - val_mae: 0.0510\n",
            "Epoch 25/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0123 - mae: 0.0494 - val_loss: 0.0273 - val_mae: 0.0505\n",
            "Epoch 26/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0139 - mae: 0.0487 - val_loss: 0.0270 - val_mae: 0.0529\n",
            "Epoch 27/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0123 - mae: 0.0500 - val_loss: 0.0274 - val_mae: 0.0538\n",
            "Epoch 28/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0118 - mae: 0.0489 - val_loss: 0.0275 - val_mae: 0.0512\n",
            "Epoch 29/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0120 - mae: 0.0493 - val_loss: 0.0273 - val_mae: 0.0521\n",
            "Epoch 30/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 0.0124 - mae: 0.0493 - val_loss: 0.0281 - val_mae: 0.0521\n",
            "Epoch 31/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0142 - mae: 0.0493 - val_loss: 0.0268 - val_mae: 0.0516\n",
            "Epoch 32/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0125 - mae: 0.0493 - val_loss: 0.0277 - val_mae: 0.0525\n",
            "Epoch 33/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - loss: 0.0116 - mae: 0.0485 - val_loss: 0.0273 - val_mae: 0.0529\n",
            "Epoch 34/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0120 - mae: 0.0490 - val_loss: 0.0273 - val_mae: 0.0518\n",
            "Epoch 35/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0120 - mae: 0.0488 - val_loss: 0.0277 - val_mae: 0.0547\n",
            "Epoch 36/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0118 - mae: 0.0488 - val_loss: 0.0272 - val_mae: 0.0529\n",
            "Epoch 37/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0118 - mae: 0.0493 - val_loss: 0.0269 - val_mae: 0.0515\n",
            "Epoch 38/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0114 - mae: 0.0485 - val_loss: 0.0272 - val_mae: 0.0521\n",
            "Epoch 39/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0491 - val_loss: 0.0273 - val_mae: 0.0540\n",
            "Epoch 40/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0128 - mae: 0.0499 - val_loss: 0.0280 - val_mae: 0.0542\n",
            "Epoch 41/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0116 - mae: 0.0486 - val_loss: 0.0270 - val_mae: 0.0536\n",
            "Epoch 42/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 0.0131 - mae: 0.0499 - val_loss: 0.0281 - val_mae: 0.0522\n",
            "Epoch 43/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0114 - mae: 0.0487 - val_loss: 0.0279 - val_mae: 0.0536\n",
            "Epoch 44/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0121 - mae: 0.0488 - val_loss: 0.0282 - val_mae: 0.0542\n",
            "Epoch 45/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - loss: 0.0140 - mae: 0.0503 - val_loss: 0.0273 - val_mae: 0.0542\n",
            "Epoch 46/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - loss: 0.0116 - mae: 0.0488 - val_loss: 0.0279 - val_mae: 0.0544\n",
            "Epoch 47/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0114 - mae: 0.0488 - val_loss: 0.0369 - val_mae: 0.0735\n",
            "Epoch 48/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0177 - mae: 0.0681 - val_loss: 0.0314 - val_mae: 0.0621\n",
            "Epoch 49/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - loss: 0.0157 - mae: 0.0613 - val_loss: 0.0319 - val_mae: 0.0679\n",
            "Epoch 50/50\n",
            "\u001b[1m509/509\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 14ms/step - loss: 0.0152 - mae: 0.0590 - val_loss: 0.0309 - val_mae: 0.0622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "LhlQ_cP_25CY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "sample_sequence = sequences[0][:19]\n",
        "predicted_pattern = predict_pattern(model, sample_sequence, max_len)\n",
        "print(f\"Sample Sequences (Last 5): {sample_sequence[-5:]}\")\n",
        "print(f\"Predicted Pattern: {predicted_pattern}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWO0cIq51hXa",
        "outputId": "5dd2b46b-43a5-428d-b4bb-f46b302ae9a0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Sequences (Last 5): [[ 0.1169  0.2562  0.1393  0.0739  0.1549  0.081   0.0892  0.1462  0.057\n",
            "   0.0966  1.3501  1.2535  0.0826  1.0669  0.9843  0.1291  0.6546  0.5255\n",
            "   0.1317  0.2112  0.0795  0.1434  0.1083 -0.0351  0.0869  0.2072  0.1203\n",
            "   0.1027  1.1307  1.028   0.1301]\n",
            " [ 0.127   0.1839  0.0569  0.0911  0.1381  0.047   0.0895  0.1774  0.0879\n",
            "   0.0739  0.6069  0.533   0.0781  0.8047  0.7266  0.1305  0.202   0.0715\n",
            "   0.1204  0.1746  0.0542  0.1338  0.1521  0.0183  0.0774  0.1954  0.118\n",
            "   0.0942  0.2643  0.1701  0.0631]\n",
            " [ 0.1016  0.1799  0.0783  0.0792  0.1434  0.0642  0.076   0.1412  0.0652\n",
            "   0.0837  0.8381  0.7544  0.1159  0.8525  0.7366  0.1154  0.3701  0.2547\n",
            "   0.1     0.1531  0.0531  0.164   0.1186 -0.0454  0.0914  0.1954  0.104\n",
            "   0.1053  0.2385  0.1332  0.0771]\n",
            " [ 0.1056  0.1755  0.0699  0.0781  0.1391  0.061   0.0898  0.1613  0.0715\n",
            "   0.0826  0.77    0.6874  0.0718  0.6947  0.6229  0.131   0.486   0.355\n",
            "   0.0692  0.1609  0.0917  0.1262  0.0697 -0.0565  0.0772  0.1944  0.1172\n",
            "   0.1169  0.2976  0.1807  0.081 ]\n",
            " [ 0.1177  0.2237  0.106   0.0837  0.188   0.1043  0.0919  0.1803  0.0884\n",
            "   0.0818  0.7784  0.6966  0.0932  0.5635  0.4703  0.1014  0.2954  0.194\n",
            "   0.056   0.216   0.16    0.09    0.0135 -0.0765  0.1162  0.2526  0.1364\n",
            "   0.0895  0.6565  0.567   0.0874]]\n",
            "Predicted Pattern: [0.14464578 0.2767298  0.14890203 0.12436    0.22353011 0.11554633\n",
            " 0.12226755 0.1984438  0.09065552 0.11574528 0.7118192  0.5981429\n",
            " 0.0922296  0.5956886  0.50897735 0.13992088 0.25911194 0.13227418\n",
            " 0.12625118 0.18489067 0.06889188 0.14818335 0.15446022 0.01318172\n",
            " 0.12445833 0.22845058 0.11474985 0.1392954  0.35958803 0.23693667\n",
            " 0.10376108]\n"
          ]
        }
      ]
    }
  ]
}