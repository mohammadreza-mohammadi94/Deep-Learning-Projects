# -*- coding: utf-8 -*-
"""Typing Pattern Recognition (RNN).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZWE8ZSyqRNx_kzZBtx71a-cWhRDM0FPQ

# Import Frameworks & Setup Enviorment
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Input, LSTM, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

import warnings
warnings.filterwarnings('ignore')

import logging
logging.basicConfig(
    format=("%(asctime)s - %(levelname)s - %(message)s"),
    level=logging.INFO,
    handlers=[
        logging.FileHandler('app_logs.log'),
        logging.StreamHandler()
    ]
)

"""# Load Dataset"""

def load_keystroke_dataset(file_path):
    df = pd.read_csv(file_path)

    # Chose features
    feature_columns = [col for col in df.columns if col.startswith(('H.', 'DD.', 'UD.'))]
    df_features = df[feature_columns]

    # Normalization Data
    df_features = (df_features - df_features.min()) / (df_features.max() - df_features.min())

    # Creating sequences for each user
    sequences = []
    user_groups = df.groupby('subject')

    for user_id, group in user_groups:
        seq = group[feature_columns].values
        sequences.append(seq)

    print("Number of Users: ", len(user_groups))
    print("Number of Features: ", len(feature_columns))
    return sequences, feature_columns

"""# Prepare Data"""

def prepare_data(sequences, max_len=20):
    X, y = [], []
    for seq in sequences:
        for i in range(len(seq) - 1):
            X.append(seq[max(0, i - max_len + 1): i + 1])
            y.append(seq[i + 1])
    X = pad_sequences(X, maxlen=max_len, padding='pre', dtype='float32')
    y = np.array(y, dtype='float32')

    print(f"Number of Sequences: {len(X)}")
    print(f"Input Dimension: {X.shape}")
    print(f"Output Dimension: {y.shape}")
    return X, y

"""# Create the Model"""

def build_model(input_shape, output_dim):
    inputs = Input(shape=input_shape)
    x = LSTM(64, return_sequences=False)(inputs)
    x = Dense(32, activation='relu')(x)
    outputs = Dense(output_dim, activation='linear')(x)

    model = Model(inputs, outputs)
    model.compile(optimizer = Adam(learning_rate=0.01),
                  loss='mse',
                  metrics=['mae'])
    return model

"""# Prediction Method"""

def predict_pattern(model, sequence, max_len):
    padded_sequence = pad_sequences([sequence[-max_len:]], maxlen=max_len, padding='pre', dtype='float32')
    prediction = model.predict(padded_sequence, verbose=0)
    return prediction[0]

"""# Run And Train the Model"""

file_path = '/content/DSL-StrongPasswordData.csv'
# Load & preprocess
sequences, feature_columns = load_keystroke_dataset(file_path)

# data preparation
max_len = 20
X, y = prepare_data(sequences, max_len)

# input output dimension
input_shape = (max_len, X.shape[2])
output_dim = X.shape[2]

# build and train the model
model = build_model(input_shape, output_dim)
model.summary()
# train the model
history = model.fit(X, y, batch_size=32, epochs=50, validation_split=0.2, verbose=1)

# saving the model
model.save('keystroke_pattern_model.h5')

"""# Predictions"""

# Predictions
sample_sequence = sequences[0][:19]
predicted_pattern = predict_pattern(model, sample_sequence, max_len)
print(f"Sample Sequences (Last 5): {sample_sequence[-5:]}")
print(f"Predicted Pattern: {predicted_pattern}")